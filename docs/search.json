[
  {
    "objectID": "curriculum-network-analysis.html",
    "href": "curriculum-network-analysis.html",
    "title": "Social Network Analysis",
    "section": "",
    "text": "Although social network analysis (SNA) and its educational antecedents date back to the early 1900s, the popularity of social networking sites like Twitter and Facebook have raised awareness of, and renewed interests in, social networks and their influence. As the use of digital resources continues to expand in education, data collected by these educational technologies has also greatly facilitated the application of network analysis to teaching and learning. The SNA modules are designed to prepare STEM education researchers to apply network analysis in order to better understand and improve student learning and the contexts in which learning occurs. The presentations, readings, and case studies for each module draw from the excellent book, Social Network Analysis and Education (Carolan 2014). Collectively, the modules provide education researchers with an overview of social network theory, examples of network analysis in STEM educational contexts, and applied experience with widely adopted tools and techniques.",
    "crumbs": [
      "Home",
      "Curriculum",
      "Social Network Analysis"
    ]
  },
  {
    "objectID": "curriculum-network-analysis.html#module-1-network-analysis-for-newbies",
    "href": "curriculum-network-analysis.html#module-1-network-analysis-for-newbies",
    "title": "Social Network Analysis",
    "section": "Module 1: Network Analysis for Newbies",
    "text": "Module 1: Network Analysis for Newbies\nThe first module is a gentle introduction to data collection, management and visualization. The focus of our Essential Readings and case study in this lab is to help LASER Scholars gain a general understanding of key SNA concepts and terminology, as well as develop a basic comfort level with representing networks visually. Our SNA Case Study: Who’s Friends with Who in Middle School is guided by the work of Pittinsky and Carolan Pittinsky and Carolan (2008) and compares teacher perceptions and student reports of classroom middle school friendship and helps reinforce the importance of treating behavioral and cognitive classroom friendship networks and ties as distinct. Finally, the Intro to SNA Badge provides an opportunity create your own data product and to reflect on how theses concepts and techniques might apply to your own research.\n\n\n\n\nConceptual\nOverview\nAn Introduction to Social Network Analysis\n\n\n\nCode Along\nData Structures & Sociograms in R | Python\n\n\n\nReadings &\nReflection\nBackground and Basic Concepts\n\n\n\nCase Study\nWho’s Friends with Who in Middle School | R Key | Python Key\n\n\n\nBadge\nIntro to SNA\n\n\n\nModule Survey\nFeedback Form After Finishing Module",
    "crumbs": [
      "Home",
      "Curriculum",
      "Social Network Analysis"
    ]
  },
  {
    "objectID": "curriculum-network-analysis.html#module-2-network-management-measurement",
    "href": "curriculum-network-analysis.html#module-2-network-management-measurement",
    "title": "Social Network Analysis",
    "section": "Module 2: Network Management & Measurement",
    "text": "Module 2: Network Management & Measurement\nModule 2 moves beyond basic concepts of network analysis and takes a closer look at the collection, management, and measurement of network data. Our Essential Readings examine the different levels at which social networks can be analyzed, as well as common network measures for describing properties of complete networks. Our Case Study: A Tale of Two MOOCs is based on a study by Kellogg, Booth, and Oliver (2014) and compares discussion networks from two courses using an open educational dataset prepared by Kellogg and Edelmann (2015) as part of the Friday Institute’s work around Massively Open Online Courses for Educators (MOOC-Eds). Finally, the Measurement Badge provides an opportunity create your own data product and to reflect on how theses concepts and techniques might apply to your own research.\n\n\n\n\nConceptual\nOverview\nData Collection & Quality\n\n\n\nCode Along\nDensity, Reciprocity, & Centrality with R | Python\n\n\n\nReadings &\nReflection\nData Management & Network Measurement\n\n\n\nCase Study\nA Tale of Two MOOCs | R Key | Python Key\n\n\n\nBadge\nNetwork Measurement Badge\n\n\n\nModule Survey\nFeedback Form After Finishing Module",
    "crumbs": [
      "Home",
      "Curriculum",
      "Social Network Analysis"
    ]
  },
  {
    "objectID": "curriculum-network-analysis.html#module-3-groups-positions-egocentric-analysis",
    "href": "curriculum-network-analysis.html#module-3-groups-positions-egocentric-analysis",
    "title": "Social Network Analysis",
    "section": "Module 3: Groups, Positions, & Egocentric Analysis",
    "text": "Module 3: Groups, Positions, & Egocentric Analysis\nModule 3 shifts the focus from complete network analysis and zooms in on methods and measures for analyzing groups, positions, and individual actors. Our Essential Readings and case study explore both “top-down” and “bottom-up” approaches to identify a network’s groups and extend measures introduced in the previous lab to identify individuals central to the network. Our SNA Case Study: Hashtag Common Core is inspired by the work of Supovitz et al. (2017) who examined groups and key actors that emerged during the intense Twitter debate surrounding the Common Core State Standards. You can learn more about their work on the expansive and interactive website for the #COMMONCORE Project. Finally, the Groups & Egos Badge provides an opportunity create your own data product and to reflect on how theses concepts and techniques might apply to your own research.\n\n\n\n\nConceptual\nOverview\nGroup Identification in Networks\n\n\n\nCode Along\nComponents, Cliques & Key Actors with R | Python\n\n\n\nReadings &\nDiscussion\nGroups, Positions, and Egocentric Analysis\n\n\n\nCase Study\nHashtag Common Core | R Key | Python Key\n\n\n\nBadge\nGroups & Egos\n\n\n\nModule Survey\nFeedback Form After Finishing Module",
    "crumbs": [
      "Home",
      "Curriculum",
      "Social Network Analysis"
    ]
  },
  {
    "objectID": "curriculum-network-analysis.html#module-4-statistical-inference-network-models",
    "href": "curriculum-network-analysis.html#module-4-statistical-inference-network-models",
    "title": "Social Network Analysis",
    "section": "Module 4: Statistical Inference & Network Models",
    "text": "Module 4: Statistical Inference & Network Models\nModule 4 wraps up our work with SNA and examines recent advances in inferential statistics that can be used to make predictions from social network data and test hypotheses we have about a network of interest. Through our Essential Readings, we’ll learn about different techniques that make use of simulations to model network data and how these statistical models are used to address questions that more completely reflect the complexity of educational settings. For example, our SNA Case Study: Birds of a Feather Lead Together is inspired by the work of Daly and Finnigan (2011) makes use of Exponential Random Graph Models (ERGMs) to examine social processes (e.g. reciprocity and homophily) that might explain how school and district-level leaders select peers for collaboration or confidential exchanges. Finally, the Models & Inference Badge provides an opportunity create your own data product and to reflect on how theses concepts and techniques might apply to your own research.\n\n\n\n\nConceptual\nOverview\nNetwork Inference & Applications\n\n\n\nCode Along\nIntro to ERGMs with R | Python\n\n\n\nReadings &\nDiscussion\nNetwork Modeling & Inference\n\n\n\nCase Study\nBirds of a Feather Lead Together | R Key | Python Key\n\n\n\nBadge\nModels & Inference\n\n\n\nModule Survey\nFeedback Form After Finishing Module",
    "crumbs": [
      "Home",
      "Curriculum",
      "Social Network Analysis"
    ]
  },
  {
    "objectID": "curriculum-network-analysis.html#microcredential",
    "href": "curriculum-network-analysis.html#microcredential",
    "title": "Social Network Analysis",
    "section": "Microcredential",
    "text": "Microcredential\nThe culminating activity for the SNA Modules is designed to provide you some space for independent analysis of a self-identified data source. To earn your SNA Microcredential, you are required to demonstrate your ability to formulate a basic research question appropriate to a social network context, wrangle and analyze relational data, and communicate key findings. Your primary goal for this analysis is to create a simple data product that illustrates key findings by applying the knowledge and skills acquired from the essential readings and case studies.\n\n\n\n\nMicrocredential\nSocial Network Analysis and Education",
    "crumbs": [
      "Home",
      "Curriculum",
      "Social Network Analysis"
    ]
  },
  {
    "objectID": "curriculum-design.html",
    "href": "curriculum-design.html",
    "title": "Modular by Design",
    "section": "",
    "text": "The LASER Institute curriculum is modular by design and consists of instructional modules that can be assembled into multiple distinct semester-long courses, incorporated into existing courses, or used individually for workshops, webinars, or other learning experiences. This design enables instructors to tailor content and activites for learners with different disciplinary backgrounds and to incorporate them as needed into new or existing programs, thereby expanding high-quality educational opportunities in LA for institutions that lack the resources to create these materials from scratch.",
    "crumbs": [
      "Home",
      "Institute",
      "Modular by Design"
    ]
  },
  {
    "objectID": "curriculum-design.html#design-principles",
    "href": "curriculum-design.html#design-principles",
    "title": "Modular by Design",
    "section": "Design Principles",
    "text": "Design Principles\nThe guiding design principle of the LASER BEAM curriculum, setting it apart from existing programs in learning analytics and educational data science, is a close connection between exemplary STEM education research and hands-on experience analyzing real-world datasets. This connection is essential for building the competencies necessary to carry out high-quality education research in STEM fields and to enable researchers to integrate methodological strategies and practices with theoretical and practical issues in STEM education. Guiding design principles the LASER curriculum include:\n\nResearch Connections. A close connection between exemplary STEM education research and hands-on experience analyzing real-world datasets.\nScaffolded Activities. Activities are carefully scaffolded to ease learners into the conceptual and technical aspects of learning analytics and to gradually release instructor supports.\nHands-On Programming. Experience using modern, industry standard analytic tools like R and Python to carry out essential data science workflow processes.\nReal-World Data. real-world datasets from a wide range of sources such as MOOCs, student information systems, and log data from digital learning platforms.\nTopic Deep Dives. Each Module Opportunities for participants to explore key topics in-depth through Essential Readings and coding Case Studies.\nLowered Barriers. Activities are designed to lower the barriers faced by researchers with little programming experience or research backgrounds in advanced methods.",
    "crumbs": [
      "Home",
      "Institute",
      "Modular by Design"
    ]
  },
  {
    "objectID": "curriculum-design.html#modules-topics",
    "href": "curriculum-design.html#modules-topics",
    "title": "Modular by Design",
    "section": "Modules Topics",
    "text": "Modules Topics\nLASER modules cover a broad range of both introductory and advanced methods frequently leveraged by LA researchers and explicitly illustrate how these methods have been applied in STEM education research. Introductory modules will focus on basic concepts pertaining to each research method and proficiency with software tools commonly employed in LA and data science more broadly (i.e., R, Python, GitHub, APIs) and focus on topics pertaining to data-intensive research workflows (Krumm et al., 2018). Modules addressing advanced methods focus on a range of exploratory and modeling techniques including supervised machine learning, unsupervised learning, relationship mining, topic modeling and LLMs, knowledge tracing and knowledge graphs, and social and epistemic network analysis.\n\n\n\n\n\n\n\n\n\n\nResearch Methods\nModule 1\nModule 2\nModule 3\nModule 4\n\n\n\n\nLA Workflows\nData Wrangling\nExploratory Analysis\nModeling Basics\nData Products\n\n\nSupervised Learning (SL)\nSL Basics\nFeature Engineering \nModel Tuning\nDiagnostic Metrics\n\n\nUnsupervised Methods\nUM Basics\nClustering\nFactor Analysis\nKnowledge Structures\n\n\nText Mining (TM)\nTM Basics\nTopic Modeling\nText Classification\nLarge Language Models\n\n\nRelationship Mining (RM)\nRM Basics\nCorrelation Mining\nAssociation and Sequential Rules\nAssociation Rule Metrics\n\n\nKnowledge Tracing (KT)\nKT Basics\nBKT family \nPFA/LKT families\nDKT family\n\n\nSocial Network Analysis (SNA)\nSNA Basics\nMeasurement\nPositions & Groups\nNetwork Modeling\n\n\nEpistemic Network Analysis (ENA)\nENA Basics\nVisualizing Networks\nQuantitative Analysis\nAdvanced Applications\n\n\n\nInterwoven within and across modules, and as appropriate to each method, are topics designed to deepen learners’ understanding of LA approaches, applications, and legal and ethical issues. Specifically, topics will include but are not limited to reproducible research and open-science standards; types of data used in LA and the methods for their collection; applications of LA to STEM educational contexts such as recommendation and intelligent tutoring systems, adaptive learning and curriculum design, and students at risk of failing a course; and legal and ethical considerations such as student privacy, data ethics and algorithmic bias. In addition, learners are introduced to frameworks and approaches such as research-practice partnerships to prepare them to work closely with educational organizations to improve STEM outcomes at the local, district and state level.",
    "crumbs": [
      "Home",
      "Institute",
      "Modular by Design"
    ]
  },
  {
    "objectID": "curriculum-design.html#module-activities",
    "href": "curriculum-design.html#module-activities",
    "title": "Modular by Design",
    "section": "Module Activities",
    "text": "Module Activities\nEach instructional module consist of carefully scaffolded activities designed to prepare participants for collaborative, data-intensive research, and to lower the barriers faced by scholars with little programming experience or research backgrounds in advanced methods. These activities provide opportunities for participants to explore key topics in-depth and gain hands-on experience using analytic tools like R and Python to carry out essential data science workflow processes, including advanced methods for machine learning and text mining. In each module, participants will also explore how these methods have been applied by researchers in STEM education contexts and work with corresponding real-world datasets from a wide range of sources such as MOOCs, student information systems, and log data from digital learning platforms.\n\nIntroductory Presentations\n\nConceptual Overviews\nEach module includes a presentation(see example) that introduces of key concepts, terminology, and applications as they relate to each corresponding research methods and their associated techniques. Conceptual Overviews are facilitated by instructors and include opportunites for discussions, questions, and practical activities, enabling participants to demonstrate their grasp of the material. This session aims to equip learners with the knowledge to apply these advanced research methods in their work, fostering innovation in STEM education.\n\n\nCode-Alongs\nThe second presentation provides a short but highly structured coding (see example) activity that demonstrates key packages and functions required for specific data analysis techniques highlighted in each unit and an exemplary research study. Both presentations include prompts for discussion to check participant understanding and connect content with their personal and professional research interests. Recorded versions of these presentations, as well as select presentations from Baker’s BDEMOOC, will also be provided on the LASER BEAM website to support independent learners. \n\n\n\nInstructional Deep Dives\n\nReadings & Reflection\nEssential Readings (see example) are curated for participants to help them dive deeper into LA concepts, techniques, and applications introduced in presentation and case studies. Each module also includes an exemplary research paper that illustrates how techniques highlighted in each module have been applied in STEM education contexts. These papers are often used to guide coding case studies and help connect technical skills required for advanced methods with authentic research applications. Accompanying these readings are guiding questions that can be used for personal reflection or to help instructors facilitate discussion and assess their understanding of module content.\n\n\nCoding Case Studies\nCase Study assignments (see example) developed by the project team are interactive coding experiences that can be completed by learners independently or in small groups. These activities demonstrate how key data-intensive research workflow processes (i.e., wrangling, visualizing, summarizing, modeling, and communicating data) featured in exemplary STEM education research studies are implemented in R or Python. Coding case studies also provide a holistic setting to explore important foundational LA topics integral to data analysis such as reproducible research, use of APIs, student privacy, ethical consideration, and diversity and inclusion in STEM education.\n\n\nOnline Tutorials\nOpenly accessible online tutorials are curated for each module and are intended to help learners develop technical proficiency with essential software packages, functions, and programming syntax introduced during conceptual overviews, code-alongs, and case studies. Tutorials include, but are not limited to, interactive R primers, recipes, and cheatsheets available on Posit Cloud, as well as Python and intelligent-tutor based assignments that scaffold students in learning to use learning analytics methods.\n\n\n\nAssessment\n\nBadges\nEach module includes a summative assessment activity designed to help learners reflect on how the concepts and techniques introduced in each lab might apply to their own STEM education research, where they can demonstrate their technical proficiency with the analytical techniques and methods addressed in each unit. Instructors are provided with physical and digital Badges (see example) to award students upon successful completion of assessments. At the instructor’s discretion, badges can be sequenced into microcredentials that can be used to certify learners’ successful demonstration and/or application of LA methods.\n\n\nMicrocredentials\nMicrocredentials (see example) are designed for individuals seeking to validate their expertise in learning analytics are are offered for each research methods.To earn a microcredential, participants are required to demonstrate a comprehensive understanding and showcase their ability to effectively utilize learning analytics to gather, analyze, and communciate educational data to support their own research.",
    "crumbs": [
      "Home",
      "Institute",
      "Modular by Design"
    ]
  },
  {
    "objectID": "curriculum-machine-learning.html",
    "href": "curriculum-machine-learning.html",
    "title": "Supervised Machine Learning",
    "section": "",
    "text": "Machine learning is increasingly prevalent in our lives—and in educational contexts. Its role in educational research and practice is growing, albeit with some challenges and even controversy. These modules are designed to familiarize you with supervised machine learning (SML) and its applications in STEM education research. Throughout the module, we’ll explore four key questions that correspond to the focus of each of the four modules. By the end, you will have a deep understanding of the key characteristics of supervised machine learning and how to implement supervised machine learning workflows in R and Python.",
    "crumbs": [
      "Home",
      "Curriculum",
      "Supervised Machine Learning"
    ]
  },
  {
    "objectID": "curriculum-machine-learning.html#module-1-supervised-machine-learning-foundations",
    "href": "curriculum-machine-learning.html#module-1-supervised-machine-learning-foundations",
    "title": "Supervised Machine Learning",
    "section": "Module 1: Supervised Machine Learning Foundations",
    "text": "Module 1: Supervised Machine Learning Foundations\nHow is prediction different from explanation? This module provides a gentle introduction to supervised machine learning by drawing out similarities to and differences from a regression modeling approach. The case study will involve modeling the graduation rate across 1000s of higher education institutions in the United States using data from the Integrated Postsecondary Education Data System (IPEDS).\n\n\n\n\nConceptual\nOverview\nWhat is Supervised Machine Learning?\n\n\n\nCode Along\nSame Model, Different Analytic Goals\n\n\n\nReadings &\nReflection\nConsidering Models for Inference and Models for Prediction\n\n\n\nCase Study Key\nExplaining or Predicting Graduation Rates Using IPEDS | Answer Key\n\n\n\nBadge\nInitial Interpretations of a Model’s Predictions\n\n\n\nModule Survey\nFeedback Form after Finishing Module",
    "crumbs": [
      "Home",
      "Curriculum",
      "Supervised Machine Learning"
    ]
  },
  {
    "objectID": "curriculum-machine-learning.html#module-2-workflows-with-training-and-testing-data",
    "href": "curriculum-machine-learning.html#module-2-workflows-with-training-and-testing-data",
    "title": "Supervised Machine Learning",
    "section": "Module 2: Workflows With Training and Testing Data",
    "text": "Module 2: Workflows With Training and Testing Data\nBuilding on the foundations from Module 1, this session delves deeper into the workflows we will use when we are using a SML approach. Particularly, we’ll explore the roles of training and testing data and when to use them in a SML workflow. We’ll predict students’ withdrawal from a course using the Open University Learning Analytics Dataset (OULAD).\n\n\n\n\nConceptual\nOverview\nUsing Training and Testing Data in a Workflow\n\n\n\nCode Along\nHow to Split Data into Training and Testing Sets\n\n\n\nReadings &\nReflection\nWhat Makes Supervised Machine Learning Distinct\n\n\n\nCase Study\nWho Drops Online Courses? An Analysis Using the OULAD | Answer Key\n\n\n\nBadge\nAdding Additional Predictors to Improve Accuracy\n\n\n\nModule Survey\nFeedback Form after Finishing Module",
    "crumbs": [
      "Home",
      "Curriculum",
      "Supervised Machine Learning"
    ]
  },
  {
    "objectID": "curriculum-machine-learning.html#module-3-interpreting-metrics",
    "href": "curriculum-machine-learning.html#module-3-interpreting-metrics",
    "title": "Supervised Machine Learning",
    "section": "Module 3: Interpreting Metrics",
    "text": "Module 3: Interpreting Metrics\nHow is the interpretation of SML models different from more familiar models? In this module, we’ll explore and work to understand the confusion matrix that can and the various metrics (e.g., precision, recall, PPV, NPV, F-score, and AUC) that are used to interpret how good at making dichotomous predictions SML models are. We’ll again use the OULAD, augmenting the variables we used in Module 1, and we’ll introduce a more complex model—the random forest model—as an alternative to the regression models used in previous modules.\n\n\n\n\nConceptual\nOverview\nHow Good is Our Model, Really?\n\n\n\nCode Along\nAdding Classification Metrics to a Workflow\n\n\n\nReadings &\nDiscussion\nConsidering Many Metrics\n\n\n\nCase Study\nBeyond Accuracy: How to Calculate Metrics | Answer Key\n\n\n\nBadge\nMetrics for Continuous Outcome Variables\n\n\n\nModule Survey\nFeedback Form after Finishing Module",
    "crumbs": [
      "Home",
      "Curriculum",
      "Supervised Machine Learning"
    ]
  },
  {
    "objectID": "curriculum-machine-learning.html#module-4-improving-predictions-through-feature-engineering",
    "href": "curriculum-machine-learning.html#module-4-improving-predictions-through-feature-engineering",
    "title": "Supervised Machine Learning",
    "section": "Module 4: Improving Predictions Through Feature Engineering",
    "text": "Module 4: Improving Predictions Through Feature Engineering\nHow can we improve our predictions? This module introduces the concept of feature engineering to enhance model performance. We’ll explore techniques for creating new variables and refining existing ones to improve prediction accuracy. We also explore cross-validation to revise and refine our model without biasing its predictions. We’ll work with the finest-grained OULAD data—interaction data—to demonstrate key feature engineering steps.\n\n\n\n\nConceptual\nOverview\nMaking Better Predictions with Random Forests\n\n\n\nCode Along\nHow to Cross-Validate and Change the Model\n\n\n\nReadings &\nDiscussion\nDiving Deep on Features and Feature Engineering\n\n\n\nCase Study\nModeling Interactions Data with Random Forest | Answer Key\n\n\n\nBadge\nFeature Engineering Activity Types\n\n\n\nModule Survey\nFeedback Form after Finishing Module",
    "crumbs": [
      "Home",
      "Curriculum",
      "Supervised Machine Learning"
    ]
  },
  {
    "objectID": "curriculum-machine-learning.html#microcredential",
    "href": "curriculum-machine-learning.html#microcredential",
    "title": "Supervised Machine Learning",
    "section": "Microcredential",
    "text": "Microcredential\nTo earn the SML micro-credential, you will carry out an SML analysis using data of your choosing and report the results in a Quarto document. Emphasize why you are using SML (relative to regression or another approach) and use feature engineering and cross-validation to refine your model. Lastly, interpret your model carefully by going beyond reporting accuracy to report the specific metrics for the strength of your SML model’s predictions, given the particular aims of your analysis.\n\n\n\n\nMicrocredential\nSupervised Machine Learning Microcredential",
    "crumbs": [
      "Home",
      "Curriculum",
      "Supervised Machine Learning"
    ]
  },
  {
    "objectID": "curriculum-orientation.html",
    "href": "curriculum-orientation.html",
    "title": "LASER Orientation",
    "section": "",
    "text": "Instructional materials for the LASER Orientation and other modules are linked below and make extensive use of the following tools:\nTo learn more about the suite of tools used for the design and delivery of instructional activities, visit the LASER Toolkit page.",
    "crumbs": [
      "Home",
      "Curriculum",
      "LASER Orientation"
    ]
  },
  {
    "objectID": "curriculum-orientation.html#orientation-module-the-laser-toolkit",
    "href": "curriculum-orientation.html#orientation-module-the-laser-toolkit",
    "title": "LASER Orientation",
    "section": "Orientation Module: The LASER Toolkit",
    "text": "Orientation Module: The LASER Toolkit\nThe Orientation Module is designed to get learners up and running with the concepts, tools, and processes that guide the LASER curriculum. The orientation begins with a Conceptual Overview focused on the benefits of reproducible research (Gandrud 2013) and tools used by LASER to for this purpose. The Code-Along is a gentle introduction to R/Python and the data-intensive research workflow introduced by Krumm, Means, and Bienkowski (2018) and covered in greater depth by . The coding Case Study expands upon the code-along and introduces working with Quarto, an open-source scientific and technical publishing system. Finally, learners earn their first LASER Badge by publishing their work to the web.\n\n\n\n\nConceptual\nOverview\nThe LASER Toolkit & Reproducible Research\n\n\n\nCode Along\nThe Data-Intensive Research Workflow in R | Python\n\n\n\nReadings &\nReflection\nReproducible Research & DIR Workflow\n\n\n\nCase Study\nA Coding Case Study with Quarto | R Key | Python Key\n\n\n\nBadge\nLASER Orientation Badge\n\n\n\nModule Survey\nFeedback Form After Finishing Module",
    "crumbs": [
      "Home",
      "Curriculum",
      "LASER Orientation"
    ]
  },
  {
    "objectID": "institute-goals.html",
    "href": "institute-goals.html",
    "title": "Institute Goals",
    "section": "",
    "text": "The LASER Institute is a year-long professional development program for early- and mid-career researchers that aims to build their capacity for leveraging new data sources and applying computational research methods to support their existing research. The overarching goal of the LASER Institute and associated curriculum materials is to build the capacity of participating scholars in three core areas:",
    "crumbs": [
      "Home",
      "Institute",
      "Institute Goals"
    ]
  },
  {
    "objectID": "institute-goals.html#learning-objectives",
    "href": "institute-goals.html#learning-objectives",
    "title": "Institute Goals",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nThe LASER curriculum is intentionally designed and carefully scaffolded to help current and future educational researchers in to:\n\nFormulate Research Questions. Learners will understand which research questions/issues appropriately addressed by LA as compared to other analytical approaches and advanced methods;\nLeverage Digital Data. Learners will be able to identify relevant sources of education data to address both theoretical and practical issues in STEM education;\nApply Computational Methods. Learner will understand how LA techniques can be applied in STEM context and Apply computational techniques (e.g., machine learning and text mining) using a choice of packages (R or Python) to prepare, explore, and model education data;\nEvaluate their Research. Learners will be able to evaluate the technical feasibility, ethical issues, and societal constraints in using analytics to support STEM teaching and learning;\nCollaborate with Practitioners. Collaborate with educational organizations to help them learn from their own data and identify new ways to support students.",
    "crumbs": [
      "Home",
      "Institute",
      "Institute Goals"
    ]
  },
  {
    "objectID": "institute-goals.html#broadening-impacts",
    "href": "institute-goals.html#broadening-impacts",
    "title": "Institute Goals",
    "section": "Broadening Impacts",
    "text": "Broadening Impacts\nThrough renewed funding from the National Science Foundation (DRL-2321128, and DRL-2321129), the next iteration of the LASER Institute: Broadening Education in Advanced Methods (LASER BEAM) aims to greatly expand the the number of education researchers capable of leveraging advanced research methods to understand and improve student learning. To address this goal, LASER BEAM has three primary objectives:\n\nLearn from LASER. A significant portion of the Summer Workshop and Fall Online Learning Community consists of module sessions focused on a range of research methods. Modules sessions are conducted in small groups and differentiated for participants based on your selected method of interest. \nTeach with LASER. Each LASER Scholar works on a self-determined “SHARK” Goal and instructional plan for teaching other faculty or students at their home institutions. These plans are developed during the Summer Workshop and implemented during the academic year.\nNetwork at LASER. Community building activities are designed to facilitate personal and professional networking and include morning icebreakers and opportunities to connect and collaborate with fellow Scholars throughout the year.\n\nTo support participants in both learning and teaching with the LASER curriculum, this grant has three major activities designed to broaden the impact of this work:\n\nModule Development. LASER BEAM aims to create a modular curriculum composed of 25-30 distinct instructional modules that can be incorporated into semester-long courses or used individually for workshops, webinars, or other training venues. To ensure that materials can be readily adapted and implemented in a wide range of contexts, evaluation efforts will focus in part on gathering ongoing feedback from instructors to improve the curriculum.\nTrain the Trainer. Faculty will participate in an intensive, week-long Summer Institute with ongoing supports during the academic year. Both of these components are designed to prepare them in these advanced methods and to incorporate curriculum resources into graduate-level programs, courses, or workshops at their home university or research institution.\nTeach it Forward. Ultimately, LASER BEAM aims to greatly expand the number of STEM education researchers who have the expertise necessary to leverage LA and big data to support their research. To that end, the project team will provide faculty ongoing support throughout the academic year to pilot curriculum resources within graduate-level programs, courses, or workshops at their local university or research institution.",
    "crumbs": [
      "Home",
      "Institute",
      "Institute Goals"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "LASER",
    "section": "",
    "text": "The Learning Analytics in STEM Education Research (LASER) Institute is a year-long professional development program for early and mid-career scholars funded by the National Science Foundation. The LASER Institute aims to increase the number of early and mid-career scholars capable of leveraging new data sources and applying computational research methods to support their existing research.\nThis website contains all the materials needed to teach with, and learn from, the LASER Institute’s instructional materials. The website is organized into three sections:"
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "LASER",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nLocated at the Friday Institute for Educational Innovation, the LASER Institute is a collaborative effort between North Carolina State University, the University of Pennsylvania, the University of Florida, and the University of Tennessee, Knoxville.\nFor more detailed information about the project team, advisory board members, past scholars, and program highlights, visit our project page at go.ncsu.edu/laser-institute.\nThis material is based upon work supported by the National Science Foundation under Grant No. DRL-2025090, DRL-2321128, and DRL-2321129."
  },
  {
    "objectID": "curriculum-text-mining.html",
    "href": "curriculum-text-mining.html",
    "title": "Text Mining",
    "section": "",
    "text": "The transition to digital learning has made available new sources of data, providing researchers new opportunities for understanding and improving STEM learning. Data sources such as digital learning environments and administrative data systems, as well as data produced by social media websites and the mass digitization of academic and practitioner publications, hold enormous potential to address a range of pressing problems in STEM Education, but collecting and analyzing text-based data also presents unique challenges. Text mining labs address the following critical questions:",
    "crumbs": [
      "Home",
      "Curriculum",
      "Text Mining"
    ]
  },
  {
    "objectID": "curriculum-text-mining.html#module-1-tidy-text-word-counts-tm-basics",
    "href": "curriculum-text-mining.html#module-1-tidy-text-word-counts-tm-basics",
    "title": "Text Mining",
    "section": "Module 1: Tidy Text & Word Counts (TM Basics)",
    "text": "Module 1: Tidy Text & Word Counts (TM Basics)\nThis module is a gentle introduction to getting our text “tidy” so we can perform some basic word counts, look at words that occur at a higher rate in a group of documents, examine words that are unique to those document groups, and create visualizations such as word cloud. The focus of our Essential Readings and case study in this lab is to help LASER Scholars gain a general understanding of key text mining concepts and terminology, as well as develop a basic comfort level with quantifying text data and working with text data. Our Text Mining Case Study: What aspects of online professional development offerings do teachers find most valuable? is guided by the work from Friday Institute and it examines teachers’ experiences in professional development (Kellogg et al. 2012). Finally, the Intro to Text Mining Badge provides an opportunity to create your own data product and to reflect on how these concepts and techniques might apply to your own research.\n\n\n\n\nConceptual\nOverview\nText Mining Basics\n\n\n\nCode Along\nTurning Texts into Numbers\n\n\n\nReadings &\nReflection\nWhat is Text Mining?\n\n\n\nCase Study\nWhat do Teachers Find Most Valuable in Online PD? | R Key | Python Key\n\n\n\nBadge\nText Mining Basics Badge\n\n\n\nModule Survey\nFeedback Form After Finishing Module",
    "crumbs": [
      "Home",
      "Curriculum",
      "Text Mining"
    ]
  },
  {
    "objectID": "curriculum-text-mining.html#module-2-public-sentiment-and-school-reform-dictionary-methods",
    "href": "curriculum-text-mining.html#module-2-public-sentiment-and-school-reform-dictionary-methods",
    "title": "Text Mining",
    "section": "Module 2: Public Sentiment and School Reform (Dictionary Methods)",
    "text": "Module 2: Public Sentiment and School Reform (Dictionary Methods)\nThis module moves beyond basic concepts of text mining and takes a closer look at a dictionary-based text mining technique, sentiment analysis. Our Essential Readings examine the topic of opinion mining or sentiment analysis. This technique is very helpful for us to understand people’s opinions about things such as a policy. Our Text mining Case Study: Do the public like NGSS? is guided by the work of Rosenberg et al. (2021) and compares public sentiment expressed toward the Next Generation Science Standards (NGSS) and Common Core State Standards using X (twitter) data. Finally, the Sentiment Analysis Badge provides an opportunity to create your own data product and to reflect on how these concepts and techniques might apply to your own research.\n\n\n\n\nConceptual\nOverview\nSentiment Analysis\n\n\n\nCode Along\nChoosing the Right Lexicon for Sentiment Analysis\n\n\n\nReadings &\nReflection\nDictionary-Based Methods\n\n\n\nCase Study\nDo the Public Like NGSS? | R Key | Python Key\n\n\n\nBadge\nSentiment Analysis Badge\n\n\n\nModule Survey\nFeedback Form After Finishing Module",
    "crumbs": [
      "Home",
      "Curriculum",
      "Text Mining"
    ]
  },
  {
    "objectID": "curriculum-text-mining.html#module-3-large-language-models-for-qualitative-analysis",
    "href": "curriculum-text-mining.html#module-3-large-language-models-for-qualitative-analysis",
    "title": "Text Mining",
    "section": "Module 3: Large Language Models for Qualitative Analysis",
    "text": "Module 3: Large Language Models for Qualitative Analysis\nThis module wraps up our work with text mining and examines recent advances in using large language models to code qualitative data (i.e., interview transcripts, group discussions, and open-ended responses). Through our essential readings, we’ll learn about this technique. Our Text Mining Case Study: What are high school students’ machine learning literacy before and after participating in an AI curriculum? is inspired by the need to assess machine learning literacy and use automated assessment for real-time intervention in the field of AI education. Finally, the Large Language Model Badge provides an opportunity to create your own data product and to reflect on how these concepts and techniques might apply to your own research.\n\n\n\n\nConceptual\nOverview\nLarge Language Models\n\n\n\nCode Along\nIn-Context Learning\n\n\n\nReadings &\nDiscussion\nLLM for Qualitative Analysis\n\n\n\nCase Study\nWhat are High School Students’ Machine Learning Literacy? | R Key | Python Key\n\n\n\nBadge\nLarge Language Models Badge\n\n\n\nModule Survey\nFeedback Form After Finishing Module",
    "crumbs": [
      "Home",
      "Curriculum",
      "Text Mining"
    ]
  },
  {
    "objectID": "curriculum-text-mining.html#module-4-topic-modeling-in-mooc-eds",
    "href": "curriculum-text-mining.html#module-4-topic-modeling-in-mooc-eds",
    "title": "Text Mining",
    "section": "Module 4: Topic Modeling in MOOC-Eds",
    "text": "Module 4: Topic Modeling in MOOC-Eds\nThis module focuses on identifying “topics” by examining how words cohere into different latent, or hidden, themes based on patterns of co-occurrence of words within documents. Our Essential Readings introduces this unsupervised machine learning technique. Our Text Mining Case Study: What are participants discussing in forums? is guided by the work from Friday Institute and it explores ideas or issues that emerged in the discussion forums in a MOOC-ed course (Akoglu, Lee, and Kellogg 2019). Finally, the Topic Modeling Badge provides an opportunity to create your own data product and to reflect on how these concepts and techniques might apply to your own research.\n\n\n\n\nConceptual\nOverview\nTopic Modeling \n\n\n\nCode Along\nLatent Dirichlet Allocation\n\n\n\nReadings &\nDiscussion\nIntroduction to Topic Modeling\n\n\n\nCase Study\nWhat are Participants Discussing in Forums? | R Key | Python Key\n\n\n\nBadge\nTopic Modeling Badge\n\n\n\nModule Survey\nFeedback Form After Finishing Module",
    "crumbs": [
      "Home",
      "Curriculum",
      "Text Mining"
    ]
  },
  {
    "objectID": "curriculum-text-mining.html#microcredential",
    "href": "curriculum-text-mining.html#microcredential",
    "title": "Text Mining",
    "section": "Microcredential",
    "text": "Microcredential\nThe culminating activity for the TM Modules is designed to provide you some space for independent analysis of a self-identified data source. To earn your TM Microcredential, you must demonstrate your ability to formulate a relevant research question for text mining, effectively manage and analyze text data, and clearly communicate your key findings. Your primary goal for this analysis is to create a simple data product that illustrates key findings by applying the knowledge and skills acquired from the essential readings and case studies.\n\n\n\n\nMicrocredential\nText Mining in Education",
    "crumbs": [
      "Home",
      "Curriculum",
      "Text Mining"
    ]
  },
  {
    "objectID": "instruction-tech.html",
    "href": "instruction-tech.html",
    "title": "LASER Toolkit",
    "section": "",
    "text": "The LASER Institute uses a suite of interactive tools for the design and delivery of instructional activities:",
    "crumbs": [
      "Home",
      "Instruction",
      "LASER Toolkit"
    ]
  },
  {
    "objectID": "instruction-tech.html#github",
    "href": "instruction-tech.html#github",
    "title": "LASER Toolkit",
    "section": "GitHub",
    "text": "GitHub\n\nGithub is used for hosting the LASER website and instructional materials. All files and and source code for the is housed on the LASER Institute GitHub organization site and deployed using GitHub Pages, an all-in-one platform deploying dynamic websites from Git. Housing all materials on GitHub allows for version control and collaborative editing of curriculum materials as well as the addition of new materials that may be developed by participants.\nCreate a free GitHub account at: https://github.com/signup.\nNote: You can now connect Github CoPilot to your Posit Cloud projects individually. You must have access to Github CoPilot through your Github account. Github’s CoPilot is a AI PairProgrammer that you can enable with RStudio. To read more about the set up check out Posit’s User Guide.\nVisit our LASER Institute GitHub site at: go.ncsu.edu/laser-github",
    "crumbs": [
      "Home",
      "Instruction",
      "LASER Toolkit"
    ]
  },
  {
    "objectID": "instruction-tech.html#posit-cloud",
    "href": "instruction-tech.html#posit-cloud",
    "title": "LASER Toolkit",
    "section": "Posit Cloud",
    "text": "Posit Cloud\n\nThe LASER Institute makes extensive use of, and highly recommends, Posit Cloud for our LASER Learning modules. Posit Cloud lets you access Posit’s powerful set of data science tools, right in your browser with no installation or complex configuration required.\nRegister for a free Posit Cloud account at: https://login.posit.cloud/register.\n\nLASER Learners Workspace\nThe LASER Learners Workspace is where we host the interactive R and Python module activities. This workspace contains RStudio “projects” for each method area, each with their own working directory, workspace, installed packages, and source documents.\nTo access this workspace, use the following link: go.ncsu.edu/laser-learners.\n\n\nLASER Instructors Workspace\nThe LASER Instructors Workspaceis where instructors can customize and adapt the curriculum materials you plan to use for your own webinar, workshop or course.\nTo access this workspace, use the following link: go.ncsu.edu/laser-instructors\n\n\nPosit Recipes & Cheat Sheets\nFor R users, we highly recommend taking advantage of the great resources provided through Posit Cloud for learning R. For example, Posit Recipes provide a collection of R code snippets and instructions featuring up-to-date best practices for coding in R. Posit Cheat Sheets also provide handy printable reference sheets to commonly used packages and their essential functions, including example code for testing them out.",
    "crumbs": [
      "Home",
      "Instruction",
      "LASER Toolkit"
    ]
  },
  {
    "objectID": "instruction-tech.html#rstudio-ide",
    "href": "instruction-tech.html#rstudio-ide",
    "title": "LASER Toolkit",
    "section": "RStudio IDE",
    "text": "RStudio IDE\n\nRStudio Desktop is a free desktop application of the RStudio Integrated Developer Environment (IDE) that runs on Windows, MacOS or Linux. Its advantages over Posit Cloud include offline access, full control over the local environment, customization options, data privacy and security, and the ability to leverage the full resources of your local machine, such as CPU, memory, and storage. While we will be using RStudio through Posit Cloud for the LASER Institute, we recommend shifting to RStudio Desktop for your own research. \nThough we will primarily use Posit Cloud for data analysis activities using R or Python, you are welcome to adapt and complete these activities using a Integrated Developer Environment (IDE) of your preference such as Jupyter Labs, Visual Studio, Google Collab, or PyCharm. Please note that support by the project team for the alternative IDEs is very limited so we will rely on those in our scholar community with expertise to assist.",
    "crumbs": [
      "Home",
      "Instruction",
      "LASER Toolkit"
    ]
  },
  {
    "objectID": "instruction-tech.html#quarto",
    "href": "instruction-tech.html#quarto",
    "title": "LASER Toolkit",
    "section": "Quarto",
    "text": "Quarto\n\nQuarto is an open-source scientific and technical publishing system used for creating reproducible, production quality articles, presentations, dashboards, websites, blogs, and books in HTML, PDF, MS Word, ePub, and more. Quarto can be used with R, Python, and other programming languages and is used extensively throughout the institute. All LASER Institute instructional materials, including this website, are created with Quarto.\nQuarto Pub is a free and easy web publishing platform for Quarto docs. To publish the documents via Quarto Pub, however, you will first need to create an account.\nTo create a Quarto Pub account, sign up here: https://quartopub.com/sign-up\nNote: If you are using RStudio Desktop, you may need to download and install Quarto here: https://quarto.org/docs/get-started/\nTo interact with a simple example data dashboard built with Quarto for LASER visit: https://sbkellogg.quarto.pub/final-grades-and-hours-logged/#plots",
    "crumbs": [
      "Home",
      "Instruction",
      "LASER Toolkit"
    ]
  },
  {
    "objectID": "instruction-tech.html#slack",
    "href": "instruction-tech.html#slack",
    "title": "LASER Toolkit",
    "section": "Slack",
    "text": "Slack\n\nThroughout the year, we provide ongoing asynchronous support and communication through Slack (http://slack.com), a web-based app that allows for text messaging, voice and video calls, and media and file sharing either in private chats or as part of communities called “workspaces.” Slack runs on Web, Windows, Linux, MacOS, Android, Windows Phone and iOS.\nTo join our LASER Institute workspace on Slack, create an account and visit: https://go.ncsu.edu/laser-slack.",
    "crumbs": [
      "Home",
      "Instruction",
      "LASER Toolkit"
    ]
  },
  {
    "objectID": "institute-components.html",
    "href": "institute-components.html",
    "title": "Program Components",
    "section": "",
    "text": "The LASER Institute is a year-long blended training program consisting of two core components:",
    "crumbs": [
      "Home",
      "Institute",
      "Program Components"
    ]
  },
  {
    "objectID": "institute-components.html#summer-workshop",
    "href": "institute-components.html#summer-workshop",
    "title": "Program Components",
    "section": "Summer Workshop",
    "text": "Summer Workshop\nLASER BEAM participants begin their program with an intensive 5-day summer training program hosted by the Friday Institute for Educational Innovation at North Carolina State University. The Summer Workshop takes place in July and is taught by NC State and Penn faculty and and includes invited presentations from Advisory Board members, as well as pre-workshop preparation (e.g., introductions and needs assessment) for participants beginning earlier that spring.\nTo attend to the needs of STEM education faculty and researchers with varying degrees of expertise in LA, the Summer Institute provide both a beginner track and an advanced track to support faculty development, with approximately half of the participants in each track. The Summer Institute schedule outlined below provides an overview of the sequence of activities currently planned, recognizing that some adjustments be necessary based on the needs assessment and specific modules participants are interested in teaching and/or learning from. Each of these activities is described in more detail below.\n\nPre-Institute Preparation\nAs part of the application process, participants complete a needs assessment to identify their teaching interests, experience with software packages, and skills and knowledge in relation to LA and advanced methods. This assessment be used to identify the appropriate track for their Summer Institute experience and help guide the content, structure and sequence of their 5-day professional development. Participants are also provided a LASER Institute Welcome Packet provided details about the program along with a pre-institute checklist to help the prepare for the institute. For example, participants on the beginner track are required to engage in pre-institute tutorials beginning in May and which must be completed prior to the workshop to demonstrate their preparation and commitment to LASER BEAM. Finally, all participants engage in an initial community building activity designed to familiarize participants with the social platform that be used throughout LASER BEAM as part of the Online Community and provide them with an opportunity to get to know each other prior to the Summer Institute.\n\n\nWorkshop Schedule\n\n\n\n\n\n\n\n\n\n\n\nEST\nMonday\nTuesday\nWednesday\nThursday\nFriday\n\n\n9:00 - 9:30\nLASER Welcome\nCommunity Building\nCommunity Building\nCommunity Building\nCommunity Building\n\n\n9:40 - 11:00\nLASER Orientation\nModule Session 1\nModule Session 2\nModule Session 3\nModule Session 4\n\n\n11:15 - 12:30\nOrientation Continued\nModule Session\nModule Session\nModule Session\nModule Session\n\n\n1:30 - 2:10\nGuest Speaker\nGuest Speaker\nGuest Speaker\nGuest Speaker\nGuest Speaker\n\n\n2:15 - 3:00\nModule Intro\nModule Session\nModule Session\nModule Session\nLASER Closing\n\n\n3:00 - 3:45\nPedagogy Session\nPedagogy Session\nPedagogy Session\nPedagogy Session\nEvaluation\n\n\n4:00 - 5:00\nDesign Session\nDesign Session\nDesign Session\nDesign Session\nEarly Exit\n\n\n\n\n\nCommunity Building\nCommunity building activities are critical in supporting and affirming sustained participation in LA and data science initiatives, particularly for novice learners and scholars from underrepresented groups Arif et al. (2021). Consequently, LASER BEAM incorporate identity-affirming activities each day of the workshop to help participants learn more about each other and create a sense of community Booth and Kellogg (2015). By sharing their backgrounds, interests, and experiences, participants identify commonalities and differences. This create a space for participants to learn from each other and build on each other’s strengths.\n\n\n\nPedagogy Sessions\nParticipants in both the beginner and advanced tracks engage in whole group sessions to support them in adapting materials for their own instructional programs. Sessions focus on a range of topics, from understanding the design principles behind the LASER BEAM curriculum to setting up the infrastructure necessary for learners to fully participate in module activities. Pedagogy sessions throughout the week focus on the nuts and bolts of teaching the curriculum, including topics such as tools and approaches for facilitating in-person and online discussion, assessment and grading of assignments, and logistics for instructional delivery. For example, on Day 1 (Monday) participants are introduced to the LASER Toolkit, a powerful set of data science and instructional tools that can be accessed through an internet browser and used for assigning, supporting, and assessing instructional activities such as the interactive coding case studies and tutorials highlighted in Section 2c.\n\n\nModule Sessions\nSessions focused on learning from LASER curriculum modules are conducted in small groups and differentiated for participants in the beginner and the advanced track based upon the needs assessment administered prior to the Summer Institute. These sessions focus on the instructional materials from which participants both learn from and use to train learners at their home institutions. Participants in the beginner track focus on 4 introductory modules to develop their foundational knowledge and skills (see Section 2c) necessary for more advanced methods. Advanced track participants engage in 4 module sessions focused on more advanced topics such as text classification and deep knowledge tracing. Sessions be facilitated by members of the project team, who model instructional best practices for use of these materials and participants in both tracks work through select module activities just as would be expected from the students and faculty they plan to teach. Additionally, module sessions be offered in an online format through workshops in the fall and spring (see Online Community section). This allow the project team to both address topics not covered during the summer institute and to model instructional delivery in a purely online context.\n\n\n\nDesign Sessions\nEach day end with small group activities to assist participants in designing a customized instructional plan at their home institutions, where they consider how to incorporate curriculum resources into their own contexts. The project team collaborate with participants to choose relevant modules and activities, effective teaching methods (pedagogy), and suitable technology from our training resources that meet the needs of their learners. The team also work with participants in aligning the chosen LA topics, pedagogy, and technology with the learners’ needs to ensure the modules are tailored to address the unique needs and preferences of their learners.\n\n\nGuest Speakers\nThese sessions draw upon the backgrounds and expertise of our Advisory Board members and other invited guests who have taught courses, workshops, and training events focused on LA and related methods. Sessions reinforce topics introduced in our module and pedagogy sessions, and help participants envision how LASER BEAM curriculum materials and activities might be adapted to fit their own contexts and institutional programs.",
    "crumbs": [
      "Home",
      "Institute",
      "Program Components"
    ]
  },
  {
    "objectID": "institute-components.html#fall-online-community",
    "href": "institute-components.html#fall-online-community",
    "title": "Program Components",
    "section": "Fall Online Community",
    "text": "Fall Online Community\nOngoing support is provided to participants during the academic year to continue their professional learning and ensure they can successfully carry out instructional plans at their home institutions. The project team provides a range of activities designed to support participants and inform curriculum refinement throughout the year. These following are guided by findings from our prior research found to be strongly associated with successful online communities:\n\nMonthly Check-Ins\nThroughout fall and spring, the project team will facilitate formal monthly check-ins with participants on progress made towards implementing instructional plans developed duringthe Summer Workshop. The check-ins will also be used to gather feedback on curricular modules used by instructors. Guest speakers from our advisory board and other invited guests will also lead sessions on LA topics during check-ins. These sessions will be informed by the community, as well as more specialized topics in advanced methods.\n\n\nVirtual Module Sessions\nThese session are offered several times each month so participants can learn about research methods they were unable to experience during the Summer Institute, as well to model instructional use of the modules in a fully online context. The workshops are led by members of the project team as well as by past LASER Scholars.\n\n\n\nAsynchronous Activities\nFacilitated discussion channels and informal Q&As are hosted on our Slack workspace, which includes both current and past participants from prior LASER Institute cohorts. Discussions focus on shared problems of practice such as adapting instructional modules to local contexts or working with students who have limited programming experience, as well as topics related to module content such as R packages, conceptual overviews, and essential readings. \n\n\nResource Repositories\nA key deliverable of this grant is a freely available website that houses all the curriculum materials needed to teach, and learn from, the LASER curriculum. These materials consist of both project team and member-generated content hosted on GitHub and this website. These websites include materials for each module as well as supporting materials for instructors such as pedagogical tips, information on computing infrastructure, technology stack, and logistics for set up.",
    "crumbs": [
      "Home",
      "Institute",
      "Program Components"
    ]
  },
  {
    "objectID": "instruction-course.html",
    "href": "instruction-course.html",
    "title": "Syllabus Example",
    "section": "",
    "text": "As the use of digital resources continues to expand in education, an unprecedented amount of new data is becoming available to educational researchers and practitioners. In response, Learning Analytics (LA) has emerged over the past decade as an interdisciplinary field encompassing Learning (e.g. educational technology, learning and assessment sciences), Analytics (e.g. visualization, computer/data sciences), and Human-Centered Design (e.g. usability, participatory design).\nThis course will provide students with an overview of the field, examples of its use in educational contexts, and applied experience with tools and techniques for analyzing new sources of data from new perspectives. As participants gain experience in the collection, analysis, and reporting of data throughout the course, they will be better prepared to help educational organizations understand and improve learning and the contexts in which learning occurs.\nNumber of Credits: 3\nCourse Prerequisites/Co-requisites: This course has no prerequisites.\nGitHub Repository: https://github.com/sbkellogg/eci-586",
    "crumbs": [
      "Home",
      "Instruction",
      "Syllabus Example"
    ]
  },
  {
    "objectID": "instruction-course.html#introduction-to-learning-analytics-eci-586",
    "href": "instruction-course.html#introduction-to-learning-analytics-eci-586",
    "title": "Syllabus Example",
    "section": "",
    "text": "As the use of digital resources continues to expand in education, an unprecedented amount of new data is becoming available to educational researchers and practitioners. In response, Learning Analytics (LA) has emerged over the past decade as an interdisciplinary field encompassing Learning (e.g. educational technology, learning and assessment sciences), Analytics (e.g. visualization, computer/data sciences), and Human-Centered Design (e.g. usability, participatory design).\nThis course will provide students with an overview of the field, examples of its use in educational contexts, and applied experience with tools and techniques for analyzing new sources of data from new perspectives. As participants gain experience in the collection, analysis, and reporting of data throughout the course, they will be better prepared to help educational organizations understand and improve learning and the contexts in which learning occurs.\nNumber of Credits: 3\nCourse Prerequisites/Co-requisites: This course has no prerequisites.\nGitHub Repository: https://github.com/sbkellogg/eci-586",
    "crumbs": [
      "Home",
      "Instruction",
      "Syllabus Example"
    ]
  },
  {
    "objectID": "instruction-course.html#time-location",
    "href": "instruction-course.html#time-location",
    "title": "Syllabus Example",
    "section": "Time & Location",
    "text": "Time & Location\nMeeting Time: This distance education course is predominantly asynchronous. Online tools are utilized throughout the course for communication and interaction. In addition, we will use Zoom for synchronous virtual office hours, web conferencing, or whole class discussions. For optional live class meet-ups, I will send out a poll the first week of class to find a time that works for the majority of students and record these meetings for students who are not able to attend.\nVirtual Class Locations: All course materials and activities can be accessed online through NC State’s Moodle course management platform. Access http://wolfware.ncsu.edu/ and log-in with your Unity ID and password. After logging-in, locate and click on ECI 586 An Introduction to Learning Analytics to access the course site.\nStudents must have Internet access and access to a Web browser (e.g., Safari, Firefox, Chrome) to participate in this course. The Moodle course site and Web-based software required for completing course projects may only be accessed online. It is strongly recommended that students have high-speed Internet access.",
    "crumbs": [
      "Home",
      "Instruction",
      "Syllabus Example"
    ]
  },
  {
    "objectID": "instruction-course.html#instructor-information",
    "href": "instruction-course.html#instructor-information",
    "title": "Syllabus Example",
    "section": "Instructor Information",
    "text": "Instructor Information\nName: Dr. Shaun Kellogg\nEmail: shaun.kellogg\\@ncsu.edu\nOffice: Friday Institute for Educational Innovation (Room 223)\nPhone: (919) 513-8563\nHours: Appointments by Calendly Monday-Friday 8:00-4:00\nSocial: LinkedIn | GitHub",
    "crumbs": [
      "Home",
      "Instruction",
      "Syllabus Example"
    ]
  },
  {
    "objectID": "instruction-course.html#course-texts",
    "href": "instruction-course.html#course-texts",
    "title": "Syllabus Example",
    "section": "Course Texts",
    "text": "Course Texts\nThere are several required textbooks for this course, all of which are freely available online or through the NCSU Library. Supplemental course readings and content (e.g. articles, videos) will also be provided at no cost through the Moodle course site. You will also be asked to locate articles of interest for our discussions and I highly recommend that you link Google Scholar to the NCSU Library: https://www.lib.ncsu.edu/articles/google-scholar.\n\nRequired\n\nKrumm, A., Means, B., & Bienkowski, M. (2018). Learning analytics goes to school: A collaborative approach to improving education. Routledge.\nEstrellado, R. A., Freer, E. A., Mostipak, J., Rosenberg, J. M., & Velásquez, I. C. (2020). Data science in education using R.Routledge.\nLang, C., Siemens, G., Wise, A., & Gasevic, D. (Eds.). (2017). Handbook of learning analytics (2nd Edition). New York, NY, USA: SOLAR, Society for Learning Analytics and Research.\nCarolan, B. V. (2013). Social network analysis and education: Theory, methods & applications. Sage Publications.\n\n\n\nOptional\n\nSclater, N. (2017). Learning analytics explained. Taylor & Francis.\nXie, Y., Allaire, J. J., & Grolemund, G. (2018). R markdown: The definitive guide. CRC Press.\nWickham, H., & Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data (2e). “ O’Reilly Media, Inc.”.\nWickham, H. (2021). Mastering shiny. “ O’Reilly Media, Inc.”.\nHealy, K. (2018). Data visualization: a practical introduction. Princeton University Press.\nCairo, A. (2016). The truthful art: Data, charts, and maps for communication. New Riders.",
    "crumbs": [
      "Home",
      "Instruction",
      "Syllabus Example"
    ]
  },
  {
    "objectID": "instruction-course.html#software",
    "href": "instruction-course.html#software",
    "title": "Syllabus Example",
    "section": "Software",
    "text": "Software\nStudents should feel comfortable installing new software programs and navigating unfamiliar graphical user interfaces. It is also recommended that students in this class have some background knowledge of online learning environments (e.g. LMS, MOOCs, etc.).\n\nRequired Software\nThis course requires R and R Studio, which will be used to provide hands-on experience with the concepts and skills addressed in course readings.\n\nPosit Cloud (https://posit.co/products/cloud/cloud/)) provides access to Posit’s powerful set of data science tools, the RStudio IDE(https://posit.co/products/open-source/rstudio), an integrated development environment (IDE) for R and Python that includes a console and syntax-highlighting editor, as well as tools for plotting, history, debugging, and workspace management. To register for a free Posit Cloud account vist: https://login.posit.cloud/register.\nPosit Primers (https://posit.cloud/learn/primers) provide an excellent series of interactive tutorials that range from R fundamentals like basic programming syntax to complex tasks like building interactive data dashboards.\nRPubs (https://rpubs.com)) is a free and easy web publishing platform for R. Throughout the course, you will be using R Markdown documents (https://rmarkdown.rstudio.com/)), which weave together narrative text and code to produce elegantly formatted, static and dynamic outputs formats including: HTML, PDF, HTML5 slides, Tufte-style handouts, books, dashboards, shiny applications, research articles, websites, and more. To publish these documents via RPubs, however, you will first need to create an account here: https://rpubs.com/users/new.\n\n\n\nOptional Software\n\nR (https://www.r-project.org) is an open-source language and computing environment for data manipulation, analysis, and visualization. Installation files for Windows, Mac, and Linux can be found at the website for the Comprehensive R Archive Network, http://cran.r-project.org/.\nRStudio Desktop (https://posit.co/products/open-source/rstudio)) is a free desktop application of the RStudio IDE for R that runs on Windows, MacOS or Linux. Its advantages over Posit Cloud include offline access, full control over the local environment, customization options, data privacy and security, and the ability to leverage the full resources of your local machine, such as CPU, memory, and storage. While we will be using RStudio through Posit Cloud for this course, I eventually recommend shifting to RStudio Desktop if you plan to use R and RStudio beyond this course.\nPosit Cheat Sheets (https://posit.cloud/learn/cheat-sheets) also provide handy reference to commonly used packages and their essential functions, including example code for testing them out.\nDataquest (https://www.dataquest.io) offers interactive R, Python, Sheets, SQL and shell courses on topics in data science, statistics and machine learning. An email will be sent providing free access to our Dataquest team, full catalogue of courses and resources for 6 months.\nLinkedIn Learning (https://www.linkedin.com/learning) offers tutorials and training courses on R, R Studio, and Tableau. LinkedIn Learning is available at no charge to students. \nGit is a free and open source distributed version control system. Jenny Bryan’s very thorough installation and R Studio set up process for Mac and Windows can be found here: http://happygitwithr.com.\nGitHub is a web-based hosting service for version control using Git. You can create an account here: https://github.com",
    "crumbs": [
      "Home",
      "Instruction",
      "Syllabus Example"
    ]
  },
  {
    "objectID": "instruction-course.html#course-goals",
    "href": "instruction-course.html#course-goals",
    "title": "Syllabus Example",
    "section": "Course Goals",
    "text": "Course Goals\nGoals for the Introduction to Learning Analytics course are guided by the North Carolina State University motto: Think and Do. Specifically, goals for this course are twofold:\n\nDisciplinary Knowledge. Students will deepen their understanding of Learning Analytics as an emerging approach within the field of Learning Analytics, including its application in a wide range of education settings.\nTechnical Skills. Scholars will develop proficiency with the processes, tools, and techniques necessary to efficiently, effectively, and ethically apply Learning Analytics for understanding and improving learning and the contexts in which learning occurs.",
    "crumbs": [
      "Home",
      "Instruction",
      "Syllabus Example"
    ]
  },
  {
    "objectID": "instruction-course.html#student-learning-outcomes",
    "href": "instruction-course.html#student-learning-outcomes",
    "title": "Syllabus Example",
    "section": "Student Learning Outcomes",
    "text": "Student Learning Outcomes\nThe following learning objectives are aligned with the overarching objectives of the Graduate Certificate in Learning Analytics program and are embedded in each unit of the course. Students who complete this course will be able to:\n\nConceptual Foundations: Describe Learning Analytics as a discipline (e.g. history, concepts, theories, methodologies, stakeholders, legal and ethical issues) and how it has been applied to important problems, questions, and issues in education;\nData Sources & Measures: Identify and appropriately use educational data sources (e.g. Student Information and Learning Management Systems) and key student metrics;\nTool Proficiency: Efficiently and effectively apply up-to-date software and tools (i.e. R or Tableau) to implement Learning Analytics workflows for preparing, analyzing, and sharing data;\nProcesses & Techniques: Understand and apply data visualization approaches and techniques (e.g. interactive visualization and data dashboards) in order to understand and improve learning and the contexts in which learning occurs; and,\nCommunication: Clearly communicate methods, analyses, findings, and recommendations that can provide actionable insight into learning contexts for a range of education stakeholders.",
    "crumbs": [
      "Home",
      "Instruction",
      "Syllabus Example"
    ]
  },
  {
    "objectID": "instruction-course.html#course-structure-schedule",
    "href": "instruction-course.html#course-structure-schedule",
    "title": "Syllabus Example",
    "section": "Course Structure & Schedule",
    "text": "Course Structure & Schedule\nThis course is divided into four units focused on conceptualizing Learning Analytics as a research discipline and developing the foundational skills for data exploration using a range of digital data sources. The first week of each unit introduces terminology, core concepts, and applications of Learning Analytics through readings, course videos, and discussion. In the second week, we focus on developing essential technical skills necessary for data-intensive Research workflows through R software tutorials. In the third week of each unit, we apply these skills to conduct an analysis and create a data product using publicly available educational datasets.\n\n\n\n\n\n\n\nSchedule\nTopics\n\n\n\n\nWELCOME\nOVERVIEW & INTRODUCTIONS\n\n\nWeek 1\nIntroductions, syllabus review, and software setup\n\n\nUNIT 1\nWHAT IS LEARNING ANALYTICS?\n\n\nWeek 2\nReadings & Discussion: Introduction to Learning Analytics as a discipline, including a little history, key concepts, learning theories, methodologies, etc.)\n\n\nWeek 3\nR Toolkit Tutorial: Software tutorials on critical packages and key functions used to import, wrangle, explore, model, and report “tidy” data.\n\n\nWeek 4\nCase Study: A look into student-level data from online classes provided by a state-wide virtual public school.\n\n\nUNIT 2\nPARTNERSHIPS & PREDICTIVE ANALYTICS\n\n\nWeek 5\nReadings & Discussion: An examination of the use of data visualization and dashboards in Learning Analytics to understand and improve student learning.\n\n\nWeek 6\nR Toolkit Tutorial: A deeper dive into the “grammar of graphics” and development of foundational skills for creating interactive data apps.\n\n\nWeek 7\nCase Study: An exploration of aggregate student data to examine educational inequities and changes over time.\n\n\nUNIT 3\nTEXT AS DATA\n\n\nWeek 8\nReadings & Discussion: Introduction to text mining in education, including a key concepts and common techniques, and their application in educational settings.\n\n\nWeek 9\nR Toolkit Tutorial: An introduction to the Shiny package and development of interactive data apps.\n\n\nWeek 10\nCase Study: A focus on text processing, word frequencies, and sentiment lexicons to examine public opinions on Twitter around the Common Core and Next Generation Science Standards.\n\n\nUNIT 4\nA NETWORK PERSPECTIVE\n\n\nWeek 11\nReadings & Discussion: Introduction to social network analysis in education, including a key concepts and common techniques, and applications in educational settings.\n\n\nWeek 12\nR Toolkit Tutorial: Software tutorials on critical packages and key functions used to import, wrangle, explore, model, and report relational data.\n\n\nWeek 13\nCase Study: A focus on network data formats, descriptives, and sociograms to examine peer interaction in Massively Open Online Course for Educators (MOOC-Eds).\n\n\nWRAP UP\nMAKE UP & FINAL PROJECTS\n\n\nWeek 14\nMake-up Week: Final opportunity for students to complete any missing work. This week should also be used to make significant progress on your final project.\n\n\nWeek 15\nFinal Project: In lieu of a final exam, students will complete and Independent analysis and develop a data product (e.g. report, presentation, data dashboard, etc.) that demonstrates concepts learned throughout the course.",
    "crumbs": [
      "Home",
      "Instruction",
      "Syllabus Example"
    ]
  },
  {
    "objectID": "instruction-course.html#major-assignments-assessment",
    "href": "instruction-course.html#major-assignments-assessment",
    "title": "Syllabus Example",
    "section": "Major Assignments & Assessment",
    "text": "Major Assignments & Assessment\n\nHousekeeping (4 pts): Students will review the syllabus and “sign” the Online Learner Agreement sent at the beginning of the semester that outlines expectations for participating in an online course. Student will also be required to install necessary software and post a brief introduction of themselves and respond to their peers. \nReading & Discussion (24 pts): The first week of each unit introduces terminology, core concepts, and applications of an analytical approach through readings, course videos, and discussion. To help guide discussions, students are provided a set of essential questions to address and are also encouraged to explore their own areas of interest. The primary goal of course readings and discussion is to foster a deeper understanding of how Learning Analytics has been applied in educational contexts.\nR Toolkit Tutorials (24 pts): The second week of each unit, consists of tutorials for working with R packages and functions used import, wrangle, explore, and model data. The primary goal of these tutorials is to support familiarity and fluency with R syntax and key functions for data analysis.\nCase Studies (24 pts): In the third week of each unit, students will complete an interactive “case study” demonstrating how key data-intensive research workflow processes (i.e., wrangling, visualizing, summarizing, modeling, and communicating data) featured in exemplary education research studies are implemented in R. Coding case studies also provide a holistic setting to explore important foundational LA topics integral to data analysis such as reproducible research, use of APIs, ethical considerations, diversity and inclusion, and creation of useful data products.\nFinal Project (24 pts): In lieu of a final exam, students will conduct and independent analysis using a data source of their choosing and create a “data product” (e.g. report, presentation, data dashboard, etc.) demonstrating the knowledge and skills gained throughout the semester.\n\nGrading Scale: The grading scale is based on 100 points:\nA+ (97-100), A (94-96), A- (90-93), B+ (87-89), B (84-86), B- (80-83)\nC+ (77-79), C (74-76), C- (70-73), D+ (67-69), D (64-66), D- (60-63), F (59 or less)\nLate work is accepted but may be penalized at 15% per week it is late. Assignments submitted by the due date, however, may be revised and resubmitted for a higher grade by the following week. Students experiencing unforeseen circumstances with a resulting excused absence (e.g., family medical emergency) are allowed to make up work without penalty.\nCourse Feedback Expectations: Please contact your instructor via email (shaun.kellogg\\@ncsu.edu) with any questions about the course project or other assignments. Your instructor will strive to answer any emails within 24 hours (M-F) and 48 hours on the weekend, and grade submitted assignments within 5-7 days of the due date. In addition, students will be provided ongoing opportunities, and are strongly encouraged, to provide course feedback to help improve the design of current and future course implementations.",
    "crumbs": [
      "Home",
      "Instruction",
      "Syllabus Example"
    ]
  },
  {
    "objectID": "instruction-course.html#nc-state-policies",
    "href": "instruction-course.html#nc-state-policies",
    "title": "Syllabus Example",
    "section": "NC State Policies",
    "text": "NC State Policies\nAcademic Integrity: Students are bound by the academic integrity policy as stated in the code of student conduct. Therefore, students are required to uphold the university pledge of honor and exercise honesty in completing any assignment. See the website for a full explanation: http://www.ncsu.edu/policies/student_services/student_discipline/POL11.35.1.php\nN.C. State University Policies, Regulations, and Rules (PRR): Students are responsible for reviewing the PRRs which pertain to their course rights and responsibilities. These include:\n\nhttp://policies.ncsu.edu/policy/pol-04-25-05 (Equal Opportunity and Non-Discrimination Policy Statement),\nhttp://oied.ncsu.edu/oied/policies.php  (Office for Institutional Equity and Diversity),\nhttp://policies.ncsu.edu/policy/pol-1135-01 (Code of Student Conduct), and\nhttp://policies.ncsu.edu/regulation/reg-02-50-03 (Grades and Grade Point Average).\n\nUniversity Non-Discrimination Policies: It is the policy of the State of North Carolina to provide equality of opportunity in education and employment for all students and employees. Accordingly, the university does not practice or condone unlawful discrimination in any form against students, employees or applicants on the grounds of race, color, religion, creed, sex, national origin, age, disability, or veteran status. In addition, North Carolina State University regards discrimination based on sexual orientation to be inconsistent with its goal of providing a welcoming environment in which all its students, faculty, and staff may learn and work up to their full potential.\nDisabilities: Reasonable accommodations will be made for students with verifiable disabilities. In order to take advantage of available accommodations, students must register with the Disability Resource Office at Holmes Hall, Suite 304, Campus Box 7509, 919-515-7653. For more information on NC State’s policy on working with students with disabilities, please see the Academic Accommodations for Students with Disabilities Regulation (REG02.20.01).",
    "crumbs": [
      "Home",
      "Instruction",
      "Syllabus Example"
    ]
  },
  {
    "objectID": "instruction-course.html#other-important-resources",
    "href": "instruction-course.html#other-important-resources",
    "title": "Syllabus Example",
    "section": "Other Important Resources",
    "text": "Other Important Resources\n\nKeep Learning: https://dasa.ncsu.edu/students/keep-learning/\nProtect the Pack FAQs: https://www.ncsu.edu/coronavirus/frequently-asked-question\nNC State Protect the Pack Resources for Students: Resources for Students | Protect the Pack\nNC State Keep Learning, tips for students opting to take courses remotely: Keep Learning Tips for Remote Learning\nIntroduction to Zoom for students: https://youtu.be/5LbPzzPbYEw\nLearning with Moodle, a student’s guide to using Moodle: https://moodle-projects.wolfware.ncsu.edu/course/view.php?id=226\nNC State Libraries Technology Lending Program\n\nThis site is open source. Improve this page.",
    "crumbs": [
      "Home",
      "Instruction",
      "Syllabus Example"
    ]
  },
  {
    "objectID": "CODE_OF_CONDUCT.html",
    "href": "CODE_OF_CONDUCT.html",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#our-pledge",
    "href": "CODE_OF_CONDUCT.html#our-pledge",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#our-standards",
    "href": "CODE_OF_CONDUCT.html#our-standards",
    "title": "Contributor Covenant Code of Conduct",
    "section": "Our Standards",
    "text": "Our Standards\nExamples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting"
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement-responsibilities",
    "href": "CODE_OF_CONDUCT.html#enforcement-responsibilities",
    "title": "Contributor Covenant Code of Conduct",
    "section": "Enforcement Responsibilities",
    "text": "Enforcement Responsibilities\nCommunity leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#scope",
    "href": "CODE_OF_CONDUCT.html#scope",
    "title": "Contributor Covenant Code of Conduct",
    "section": "Scope",
    "text": "Scope\nThis Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement",
    "href": "CODE_OF_CONDUCT.html#enforcement",
    "title": "Contributor Covenant Code of Conduct",
    "section": "Enforcement",
    "text": "Enforcement\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at [INSERT CONTACT METHOD]. All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement-guidelines",
    "href": "CODE_OF_CONDUCT.html#enforcement-guidelines",
    "title": "Contributor Covenant Code of Conduct",
    "section": "Enforcement Guidelines",
    "text": "Enforcement Guidelines\nCommunity leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\n1. Correction\nCommunity Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n\n\n2. Warning\nCommunity Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n3. Temporary Ban\nCommunity Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n4. Permanent Ban\nCommunity Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#attribution",
    "href": "CODE_OF_CONDUCT.html#attribution",
    "title": "Contributor Covenant Code of Conduct",
    "section": "Attribution",
    "text": "Attribution\nThis Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/ code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https:// www.contributor-covenant.org/translations."
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "Attribution-ShareAlike 4.0 International",
    "section": "",
    "text": "Creative Commons Corporation (“Creative Commons”) is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an “as-is” basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible."
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "title": "Attribution-ShareAlike 4.0 International",
    "section": "Creative Commons Attribution-ShareAlike 4.0 International Public License",
    "text": "Creative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 – Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 – Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\n\nreproduce and Share the Licensed Material, in whole or in part; and\nproduce, reproduce, and Share Adapted Material.\n\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\n\n__Additional offer from the Licensor – Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter’s License You apply.\n\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\n\n\nSection 3 – License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\n\nretain the following if it is supplied by the Licensor with the Licensed Material:\n\n\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\n\n\nindicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nindicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\n\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter’s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter’s License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter’s License You apply.\n\n\n\nSection 4 – Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 – Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 – Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 – Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.t stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 – Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org"
  },
  {
    "objectID": "instruction-webinar.html",
    "href": "instruction-webinar.html",
    "title": "Webinar Example",
    "section": "",
    "text": "Welcome to An Introduction to Social Network Analysis and Education Research: Core Concepts and Applications with R! This webinar is not only part of the 2023 AERA Virtual Research Learning Series, but part of the broader work of the Learning Analytics in STEM Education Research (LASER) Institute, a professional development program for early and mid-career researchers funded by the National Science Foundation (ECR: BCSER). To help you prepare for our workshop this Thursday, August 10, 2023, from 1:00pm to 5:00pm (EST), provided below is some information about the organizational aspects of the workshop as well as the technical components you will need to fully participate.",
    "crumbs": [
      "Home",
      "Instruction",
      "Webinar Example"
    ]
  },
  {
    "objectID": "instruction-webinar.html#overview",
    "href": "instruction-webinar.html#overview",
    "title": "Webinar Example",
    "section": "Overview",
    "text": "Overview\nThis workshop is designed to introduce education researchers with little or no background in SNA to social network theory, examples of network analysis in educational contexts, and applied experience analyzing real-world data sets. To support scholars’ conceptual understanding of SNA as both a theoretical perspective and an analytical method, the instructors will provide short presentations and facilitate peer discussion on topics ranging from broad applications of SNA in educational contexts to specific approaches for data collection and storage.\nThis course will also provide you with applied experience analyzing network data through code-alongs and interactive case studies that use widely adopted tools (e.g., R, RStudio, and GitHub) and demonstrate common techniques (e.g, network visualization, measurement, and modeling). Collectively, these activities will help you both appreciate and experience how SNA can be used to understand and improve student learning and the contexts in which learning occurs.",
    "crumbs": [
      "Home",
      "Instruction",
      "Webinar Example"
    ]
  },
  {
    "objectID": "instruction-webinar.html#agenda-slides",
    "href": "instruction-webinar.html#agenda-slides",
    "title": "Webinar Example",
    "section": "Agenda & Slides",
    "text": "Agenda & Slides\n\n1:00 - 1:50 Introduction & Overview\n\nSNA LASER Learning Modules\n\n1:50 - 2:00 Break\n2:00 - 3:00 Lab 1: SNA for Newbies\n\nConceptual Overview\nCode-Along\n\n3:00 - 3:20 Break\n3:20 - 4:00 Lab 1: Case Study\n\nWho’s Friends with Who in Middle School\n\n4:00 - 5:00 Lab 2: Management & Measurement\n\nConceptual Overview\nCode-Along\n\n5:00 - 5:30 Dismiss/Break\n5:30 - 6:00 Afterparty!",
    "crumbs": [
      "Home",
      "Instruction",
      "Webinar Example"
    ]
  },
  {
    "objectID": "instruction-webinar.html#laser-institute-toolkit",
    "href": "instruction-webinar.html#laser-institute-toolkit",
    "title": "Webinar Example",
    "section": "LASER Institute Toolkit",
    "text": "LASER Institute Toolkit\n\nPosit Cloud\nFor our broader LASER Institute program and for this workshop as well, we will make extensive use of Posit Cloud (https://posit.co/products/cloud/cloud/). Posit Cloud lets you access Posit’s powerful set of data science tools like the RStudio IDE (https://posit.co/products/open-source/rstudio), an integrated development environment (IDE) for R and Python that includes a console and syntax-highlighting editor, as well as tools for plotting, history, debugging, and workspace management. Since Posit Cloud is accessed right in your browser, there is no installation or complex configuration required.\nPrior to the workshop, you will need to register for a free Posit Cloud account at: https://login.posit.cloud/register.\n\nAERA SNA Workshop 2023 Workspace\nDuring the workshop, you will need to access our AERA SNA Workshop 2023, where we will host the network-analysis RStudio project and instructional materials it contains. To access this workspace, use the following link: go.ncsu.edu/laser-learner. RStudio projects make it straightforward to divide your work into multiple contexts, each with their own working directory, workspace, history, and source documents. To learn more, visit: https://support.posit.co/hc/en-us/articles/200526207-Using-RStudio-Projects.\nIf you’ve accessed the workspace correctly, you should see something like this:\n\n\n\n\nPosit Primers & Cheat Sheets\nTo make this most of this workshop it is helpful to have some basic working knowledge of R. If you are new to R, we highly recommend taking advantage of the great resources provided through Posit Cloud for learning R. For example, Posit Recipes (https://posit.cloud/learn/recipes) provide an excellent series of interactive tutorials that range from R fundamentals like basic programming syntax to complex tasks like building interactive data dashboards. Specifically, we strongly encourage you to complete The Basics primer consisting of:\nPosit Cheat Sheets (https://posit.cloud/learn/cheat-sheets) also provide handy reference to commonly used packages and their essential functions, including example code for testing them out.",
    "crumbs": [
      "Home",
      "Instruction",
      "Webinar Example"
    ]
  },
  {
    "objectID": "instruction-webinar.html#learn-more",
    "href": "instruction-webinar.html#learn-more",
    "title": "Webinar Example",
    "section": "Learn More",
    "text": "Learn More\nFinally, if you are interested in learning more about the LASER Institute and are considering applying for our 2024 cohort, we encourage you to visit our LASER Institute website and the 2023 Welcome Packet.\nTake care and we’ll see you all soon!!\nShaun B. Kellogg, North Carolina State University\nOleksandra Poquet, Technical University of Munich\nBodong Chen, University of Pennsylvania\nJeanne M. McClure, North Carolina State University",
    "crumbs": [
      "Home",
      "Instruction",
      "Webinar Example"
    ]
  },
  {
    "objectID": "institute-la.html",
    "href": "institute-la.html",
    "title": "What is Learning Analytics?",
    "section": "",
    "text": "For an in-depth perspective on Learning Analytics, watch the inaugural LASER Institute Keynote presentation by Dr. Alyssa Wise, professor of technology and education and director of the Learning Incubator: A Vanderbilt Endeavor (LIVE), and former professor of learning sciences and educational technology and director of New York University’s Learning Analytics Research Network (LEARN).\n\nSoLAR Definition\nThe Society for Learning Analytics Research (SoLAR) defines Learning Analytics as the measurement, collection, analysis and reporting of data about learners and their contexts, for purposes of understanding and optimizing learning and the environments in which it occurs.\nAs a research and teaching field, Learning Analytics sits at the convergence of:\n\nLearning (e.g. educational research, learning and assessment sciences, educational technology);\nAnalytics (e.g. statistics, visualization, computer/data sciences, artificial intelligence); and,\nHuman-Centered Design (e.g. usability, participatory design, sociotechnical systems thinking)..\n\nLearning Analytics builds on these well established disciplines, but also seeks to leverage new opportunities through new forms of digital data computational analysis techniques from data science and AI.",
    "crumbs": [
      "Home",
      "Institute",
      "What is Learning Analytics?"
    ]
  },
  {
    "objectID": "instruction-workshop.html#learning-to-teach-with-and-learn-from-laser",
    "href": "instruction-workshop.html#learning-to-teach-with-and-learn-from-laser",
    "title": "Workshop Example",
    "section": "Learning to teach with (and learn from!) LASER",
    "text": "Learning to teach with (and learn from!) LASER\nDate: Tuesday, March 19, 2024\nTime: 1:30pm - 5:00pm\nLocation: Room J\nProject Website: go.ncsu.edu/laser-institute\nCurriculum Website: go.ncsu.edu/laser-beam\nPosit Workspace: go.ncsu.edu/laser-learners",
    "crumbs": [
      "Home",
      "Instruction",
      "Workshop Example"
    ]
  },
  {
    "objectID": "instruction-workshop.html#overview",
    "href": "instruction-workshop.html#overview",
    "title": "Workshop Example",
    "section": "Overview",
    "text": "Overview\nThe purpose of this interactive workshop is to provide a hands-on introduction to curriculum developed as part of the Learning Analytics in STEM Education Research (LASER) Institute, a professional development program for early and mid-career researchers funded by the National Science Foundation (ECR: BCSER). The intended audience for this workshop includes early-career and experienced scholars seeking who currently teach, or have a desire to teach, learning analytics methodologies. The primary aim of this workshop is to support participants interested in incorporating LASER curriculum materials into webinars, workshops, courses or programs at their home institution.\nParticipants in this workshop will learn about the design and structure of the 25+ learning modules covering a range of topics and techniques like machine learning, network analysis, and text mining. Participants will also gain hands-on experience with instructional activities such as conceptual overviews, interactive code-alongs, tutorials, case studies using Python and R, essential readings and discussion activities, and badging and microcredential opportunities. Finally, participants will learn pedagogical tips and information on the computing infrastructure, technology stack, and logistics required for leveraging these materials for their own undergraduate, graduate or professional learning programs.\nKeywords: graduate education, professional learning, professional development, STEM education, machine learning, network analysis, text mining, relationship mining, knowledge tracing",
    "crumbs": [
      "Home",
      "Instruction",
      "Workshop Example"
    ]
  },
  {
    "objectID": "instruction-workshop.html#workshop-schedule",
    "href": "instruction-workshop.html#workshop-schedule",
    "title": "Workshop Example",
    "section": "Workshop Schedule",
    "text": "Workshop Schedule\nThis session will be an interactive half-day workshop appropriate for 25-30 participants and will consist of the following schedule:\n\n1:30 - 2:00 pm\n\nLASER Team & Participant Introductions\nOverview of LASER Institute\nIntroduction to the LASER Curriculum\n\n2:00 - 3:00\n\nLASER Orientation Module\n\nConceptual Overview\nCode-Along\nCase Study (Answer Key)\n\n\n3:00 - 3:30 Coffee Break\n3:30 - 4:30\n\nLASER Orientation Continued\nSNA Curriculum Modules Exploration\nOpen Discussion\n\n4:45 - 5:00 Closing\n\nFeedback Survey\nNext steps",
    "crumbs": [
      "Home",
      "Instruction",
      "Workshop Example"
    ]
  },
  {
    "objectID": "instruction-workshop.html#background",
    "href": "instruction-workshop.html#background",
    "title": "Workshop Example",
    "section": "Background",
    "text": "Background\nTo help address this need for researchers trained in LA and related methods, the Learning Analytics in STEM Education Research (LASER) Institute was developed with the primary goal of increasing the number and the capacity of scholars capable of leveraging new data sources and computational methods (e.g., network analysis, text mining and machine learning) to support their research. With a new round of funding from the National Science Foundation (ECR: BCSER), North Carolina State University and the University of Pennsylvania are refining, expanding, and repackaging instructional resources developed for the LASER Institute into “turnkey” curriculum materials that can be used and adapted by faculty in higher education to prepare the next generation of STEM scholars.",
    "crumbs": [
      "Home",
      "Instruction",
      "Workshop Example"
    ]
  },
  {
    "objectID": "instruction-workshop.html#workshop-activities",
    "href": "instruction-workshop.html#workshop-activities",
    "title": "Workshop Example",
    "section": "Workshop Activities",
    "text": "Workshop Activities\nThe workshop will kick-off with a 30 minute introductory presentation that provides an overview of the purpose and goals of LASER Institute, including lessons learned from two virtual and one in-person cohorts of participating scholars.\nPart 1 of the workshop will provide participant hands-on experience with the following types of instructional activities included in each curriculum module:\n\nInteractive Presentations. Each module contains slide decks for two interactive presentations: the first consisting of a conceptual overview of key terminology, techniques, and applications; the second presentation providing a short but highly structured code-along activity that demonstrates key packages and functions required for specific data analysis techniques. \nCoding Case Studies. These interactive coding experiences can be completed by learners independently or in small groups and demonstrate key data-intensive research workflow processes (i.e., wrangling, visualizing, summarizing, modeling, and communicating data). \nReadings and Discussion. Essential readings are curated for participants to help them dive deeper into LA concepts, techniques, and applications introduced in presentation and case studies.\nSoftware Tutorials. Openly accessible software tutorials are curated for each module and are intended to help learners develop technical proficiency with essential software packages, functions, and programming syntax.  \nBadges & Microcredentials. Each module includes a summative assessment activity designed to help learners reflect on how the concepts and techniques introduced in each lab might apply to their own STEM education research, where they can demonstrate their technical proficiency with the analytical techniques and methods addressed in each unit.\n\nPart 2 of the workshop will consist of a presentation, facilitated discussion, and guided planning activities designed to support participants in setting up learning environments and adapting these materials for webinars, workshops, or courses at their home institution.",
    "crumbs": [
      "Home",
      "Instruction",
      "Workshop Example"
    ]
  },
  {
    "objectID": "instruction-workshop.html#workshop-goals",
    "href": "instruction-workshop.html#workshop-goals",
    "title": "Workshop Example",
    "section": "Workshop Goals",
    "text": "Workshop Goals\nThe half-day workshop serves as an extension of the LASER Institute, with the primary goal of equipping participants with high-quality curriculum materials that can be used to train faculty and students at their home institutions. To achieve this goal, this workshop is organized into three parts. Part 1 introduces participants to the curriculum materials developed by the LASER team and provides hands-on activities to help participants understand curriculum content and instructional design. Part 2 focuses on the technology infrastructure required for teaching with these materials including set up for Posit Cloud, R Studio, and Quarto. In addition, facilitators will help participants select appropriate modules for their instructional goals and develop a tentative plan to use curriculum materials for webinars, workshops, and courses at their university or research institutions. \nFinally, we recognize that there is always room for improving these curriculum materials, particularly after use in a wider range of instructional settings. Therefore, a secondary aim of this workshop is to gather feedback from participating scholars both during and after the workshop to further refine the curriculum materials. Specifically, we will incorporate opportunities throughout the workshop to solicit feedback from participants on how curriculum materials might be improved or adapted to better fit their local context and meet the needs of learners at their home institutions.",
    "crumbs": [
      "Home",
      "Instruction",
      "Workshop Example"
    ]
  },
  {
    "objectID": "instruction-workshop.html#post-workshop-engagement",
    "href": "instruction-workshop.html#post-workshop-engagement",
    "title": "Workshop Example",
    "section": "Post Workshop Engagement",
    "text": "Post Workshop Engagement\nParticipants will be invited to join the LASER community hub on Slack, which serves as a platform for building a community of practice and staying updated on future LASER events, resources and information. In addition, participants will be invited to participate in follow-up surveys designed to assess in what ways, and to what extent, participants have incorporated LASER curriculum materials into their own teaching and to gather feedback for improving these materials.",
    "crumbs": [
      "Home",
      "Instruction",
      "Workshop Example"
    ]
  },
  {
    "objectID": "instruction-workshop.html#acknowledgement",
    "href": "instruction-workshop.html#acknowledgement",
    "title": "Workshop Example",
    "section": "Acknowledgement",
    "text": "Acknowledgement\n\nThis material is based upon work supported by the National Science Foundation under Grant No. DRL-2025090, DRL-2321128, and DRL-2321129.",
    "crumbs": [
      "Home",
      "Instruction",
      "Workshop Example"
    ]
  },
  {
    "objectID": "curriculum-la-workflow.html",
    "href": "curriculum-la-workflow.html",
    "title": "Learning Analytics Workflow",
    "section": "",
    "text": "The Learning Analytics Workflow modules are designed to equip STEM education researchers with the skills to apply these analytical methods to better understand and enhance student learning and educational environments. The modules offer a comprehensive overview of the learning analytics process, starting with the characteristics of educational data and progressing through data visualization, analytical methods, and communication of findings. The presentations, readings, and case studies for each module draw from leading texts, such as Learning Analytics Goes to School (Krumm, Means, and Bienkowski 2018), as well as current research in the field, providing participants with both theoretical knowledge and practical experience. Scholars will engage in hands-on coding exercises using R and Python, tailored to their respective programming preferences, ensuring they gain practical skills in data preparation, visualization, modeling, and communication.",
    "crumbs": [
      "Home",
      "Curriculum",
      "Learning Analytics Workflow"
    ]
  },
  {
    "objectID": "curriculum-la-workflow.html#module-1-characteristics-of-data",
    "href": "curriculum-la-workflow.html#module-1-characteristics-of-data",
    "title": "Learning Analytics Workflow",
    "section": "Module 1: Characteristics of Data",
    "text": "Module 1: Characteristics of Data\nIn Module 1, scholars will learn about different types of learning environments and the characteristics of data commonly used in educational research. The module offers an introduction to the fundamental concepts of learning analytics, tailored for those new to the field or seeking to enhance their basic R or Python programming skills, particularly within STEM education contexts. Scholars will examine various data types, including interaction between instructors and students, administrative and demographic data, and student affectivity, each crucial for developing educational strategies. The hands-on component involves navigating the initial steps of the Learning Analytics workflow, such as preparing data, installing necessary packages, loading data sets, and inspecting data structures. By the end of the module, participants will have a practical understanding of how to apply these concepts through coding exercises, setting the stage for advanced analytical tasks in future modules. The Data Prep badge provides an opportunity to show your skills using the case study data or a choice of data to wrangle using the skills you learned in this module.\n\n\n\n\nConceptual\nOverview\nCharacteristics of Data in Learning Analytics\n\n\n\nCode Along\nPreparing for Research and Wrangling Data in R | Python\n\n\n\nReadings &\nReflection\nChapter 2: Data Used in Educational Data-Intensive Research\n\n\n\nCase Study\nThe Data-Intensive Research Workflow | R Key | Python Key\n\n\n\nBadge\nFoundations of Learning Analytics with R | Python\n\n\n\nModule Survey\nFeedback Form After Finishing Module",
    "crumbs": [
      "Home",
      "Curriculum",
      "Learning Analytics Workflow"
    ]
  },
  {
    "objectID": "curriculum-la-workflow.html#module-2-the-power-of-data-viz",
    "href": "curriculum-la-workflow.html#module-2-the-power-of-data-viz",
    "title": "Learning Analytics Workflow",
    "section": "Module 2: The Power of Data Viz",
    "text": "Module 2: The Power of Data Viz\nIn Module 2, scholars explore the vital role of data visualization in learning analytics. This module underscores how visual representations of data can significantly simplify the complexity of educational data, making it more comprehensible and accessible for analysis. Scholars learn to appreciate the benefits of visualization in enhancing understanding, promoting engagement, aiding decision-making, and improving communication. The module covers various types of data visualizations, such as bar charts, line graphs, scatter plots, heatmaps, and network diagrams, each chosen for their effectiveness in illustrating specific data relationships and patterns. Real-world examples are provided to showcase practical applications and the impact of effective data visualization in educational contexts. Best practices are also discussed, emphasizing the importance of knowing the audience, opting for simple designs, choosing the correct types of visualizations, providing contextual clarity, using colors strategically, and iterating based on feedback to refine the visual outputs. The Exploratory LA badge provides an opportunity to show your skills using case study data or your choice of data to visualize using the skills you learned in this module.\n\n\n\n\nConceptual\nOverview\nThe Power of Data Visualization\n\n\n\nCode Along\nExploratory Data Analysis Basics with R | Python\n\n\n\nReadings &\nReflection\nChapter 4: Legal and Ethical Issues in Learning Analytics\n\n\n\nCase Study\nIntro to Exploratory Data Analysis | R Key | Python Key\n\n\n\nBadge\nData Visualization Basics with R | Python\n\n\n\nModule Survey\nFeedback Form After Finishing Module",
    "crumbs": [
      "Home",
      "Curriculum",
      "Learning Analytics Workflow"
    ]
  },
  {
    "objectID": "curriculum-la-workflow.html#module-3-learning-analytics-methods",
    "href": "curriculum-la-workflow.html#module-3-learning-analytics-methods",
    "title": "Learning Analytics Workflow",
    "section": "Module 3: Learning Analytics Methods",
    "text": "Module 3: Learning Analytics Methods\nIn Module 3, scholars explore a variety of methods used in learning analytics. The session begins by revisiting basic concepts about the types and characteristics of data in LA. It covers five main analytical methods: predictive analytics, social network analysis, discourse analysis, text analysis, and multimodal analysis. Predictive analytics aims to forecast student performance and enhance intervention strategies. Social network analysis examines social interactions to identify key influencers and optimize collaborative learning. Discourse analysis investigates communication within educational settings to understand student engagement in critical thinking. Text analysis applies natural language processing to assess and provide feedback on text-based assignments. Lastly, multimodal analysis integrates various data sources to provide a comprehensive view of the learning process, supporting personalized educational experiences. This overview equips scholars with the knowledge to apply these methods effectively in educational research and practice. The Modeling badge provides an opportunity to show your skills using case study data or your choice of data to model using the skills you learned in this module.\n\n\n\n\nConceptual\nOverview\nMethods Used in Learning Analytics\n\n\n\nCode Along\nModeling Basics with R | Python\n\n\n\nReadings &\nDiscussion\nChapter 3: Methods Used in Learning Analytics\n\n\n\nCase Study\nIntroduction to Modeling | R Key | Python Key\n\n\n\nBadge\nData Sources in Learning Analytics with R | Python\n\n\n\nModule Survey\nFeedback Form After Finishing Module",
    "crumbs": [
      "Home",
      "Curriculum",
      "Learning Analytics Workflow"
    ]
  },
  {
    "objectID": "curriculum-la-workflow.html#module-4-data-products",
    "href": "curriculum-la-workflow.html#module-4-data-products",
    "title": "Learning Analytics Workflow",
    "section": "Module 4: Data Products",
    "text": "Module 4: Data Products\nIn Module 4, scholars will learn to communicate their analytical findings effectively, focusing on creating publication-ready products and considering ethical aspects of data presentation. They will be introduced to strategies for engaging education stakeholders through compelling data storytelling, ensuring the message is clear and accessible. The course also delves into the preparation of various communication mediums using tools like R Markdown and Flexdashboard to model and communicate insights. Additionally, this module emphasizes the importance of addressing ethical considerations such as data privacy, bias, and inclusive practices to ensure responsible use of data in educational settings. This framework prepares scholars to craft their messages thoughtfully, considering both their audience and the ethical dimensions of data use. The Communication badge provides an opportunity to show your skills using case study data or your choice of data to develop a dashboard using the skills you learned in this module.\n\n\n\n\nConceptual\nOverview\nCommunicating with Stakeholder\n\n\n\nCode Along\nData Products with R | Python\n\n\n\nReadings &\nDiscussion\nChapter 7: Five Phases of Data-Intensive Improvement\n\n\n\nCase Study\nBuilding a Basic Data Dashboard | R Key | Python Key\n\n\n\nBadge\nData Products\n\n\n\nModule Survey\nFeedback Form After Finishing Module",
    "crumbs": [
      "Home",
      "Curriculum",
      "Learning Analytics Workflow"
    ]
  },
  {
    "objectID": "curriculum-la-workflow.html#microcredential",
    "href": "curriculum-la-workflow.html#microcredential",
    "title": "Learning Analytics Workflow",
    "section": "Microcredential",
    "text": "Microcredential\nThe culminating activity for the LAW Modules is designed to provide you some space for independent analysis of a self-identified data source. To earn your LAW Microcredential, you are required to demonstrate your ability to formulate a basic research question appropriate to a social network context, wrangle and analyze relational data, and communicate key findings. Your primary goal for this analysis is to create a simple data product that illustrates key findings by applying the knowledge and skills acquired from the essential readings and case studies.\n\n\n\n\nMicrocredential\nThe Learning Analytics Workflow",
    "crumbs": [
      "Home",
      "Curriculum",
      "Learning Analytics Workflow"
    ]
  },
  {
    "objectID": "curriculum-knowledge-tracing.html",
    "href": "curriculum-knowledge-tracing.html",
    "title": "Knowledge Tracing",
    "section": "",
    "text": "The Knowledge Tracing Modules are designed to provide LASER Scholars with a comprehensive understanding and hands-on experience in various knowledge tracing methods used in digital learning platforms. Beginning with Bayesian Knowledge Tracing (BKT), scholars will build and explore classic BKT models using Python, gaining insights into its application across learning scenarios. The program then introduces Performance Factor Analysis (PFA) and Logistic Knowledge Tracing (LKT), where scholars will clean datasets and build LKT models, learning to analyze student performance involving multiple skills. Next, the modules cover Item Response Theory (IRT), equipping scholars with the principles and skills to validate educational assessments. Finally, the we wrap up this unit by diving into Deep Knowledge Tracing (DKT), where scholars will engage with deep neural network models, understanding their strengths and limitations. Throughout the modules, case studies, essential readings, and badge activities in ASSISTments will reinforce learning and application, preparing scholars to utilize these techniques effectively in educational research and practice.",
    "crumbs": [
      "Home",
      "Curriculum",
      "Knowledge Tracing"
    ]
  },
  {
    "objectID": "curriculum-knowledge-tracing.html#module-1-bayesian-knowledge-tracing",
    "href": "curriculum-knowledge-tracing.html#module-1-bayesian-knowledge-tracing",
    "title": "Knowledge Tracing",
    "section": "Module 1: Bayesian Knowledge Tracing",
    "text": "Module 1: Bayesian Knowledge Tracing\nBayesian Knowledge Tracing (BKT) (Corbett and Anderson 1994) is the most widely used student knowledge modeling framework within digital learning platforms. The BKT model provides decent-quality predictions of future performance within or outside the learning systems, interpretable models, meaningful parameters, and the ability to be applied to a range of learning situations. The goal of our Essential Readings and Case Study is to help LASER Scholars gain a theoretical understanding and practical experience with BKT. Our BKT Case Study is based on Zambrano, Zhang, and Baker (2024). You will use Python to build classic BKT models and explore some of the variations. Finally, you will complete the BKT Badge activity in ASSISTments and develop research questions utilizing a Large Language Model.\n\n\n\n\nConceptual\nOverview\nBayesian Knowledge Tracing\n\n\n\nCode Along\nBKT with ASSISTmentsBKT-BF walkthrough-PCBKT-BF walkthrough Mac\n\n\n\nReadings &\nReflection\nEssential Readings\n\n\n\nCase Study\nBayesian Knowledge Tracing with Python | Answer Key\n\n\n\nBadge\nApplying BKT in Practice\n\n\n\nModule Survey\nFeedback Form After Finishing Module",
    "crumbs": [
      "Home",
      "Curriculum",
      "Knowledge Tracing"
    ]
  },
  {
    "objectID": "curriculum-knowledge-tracing.html#module-2-performance-factor-analysis",
    "href": "curriculum-knowledge-tracing.html#module-2-performance-factor-analysis",
    "title": "Knowledge Tracing",
    "section": "Module 2: Performance Factor Analysis",
    "text": "Module 2: Performance Factor Analysis\nModule 2 introduces Performance Factor Analysis (PFA) and logistic knowledge tracing (LKT) as alternative knowledge tracing methods. LKT utilizes Logistic Regression to investigate students’ performance. Unlike BKT, each item may involve multiple skills or knowledge components (KC). With the case study, you will learn to clean the dataset and build an LKT model. Our case study is based on the work of Tirronen and Tirronen (2020). This paper discusses the application of LKT in the programming education field and the case study will guide you to practice building your LKT model in R with the example dataset. Like module 1, you will complete the LKT Badge activity in ASSISTments and develop research questions utilizing a Large Language Model.\n\n\n\n\nConceptual\nOverview\nLogistic Knowledge Tracing and PFA\n\n\n\nCode Along\nLKT walkthrough\n\n\n\nReadings &\nReflection\nEssential Readings\n\n\n\nCase Study\nPFA case study\n\n\n\nBadge\nLTK and PFA with ASSISTments\n\n\n\nModule Survey\nFeedback Form After Finishing Module",
    "crumbs": [
      "Home",
      "Curriculum",
      "Knowledge Tracing"
    ]
  },
  {
    "objectID": "curriculum-knowledge-tracing.html#module-3-item-response-theory",
    "href": "curriculum-knowledge-tracing.html#module-3-item-response-theory",
    "title": "Knowledge Tracing",
    "section": "Module 3: Item Response Theory",
    "text": "Module 3: Item Response Theory\nModule 3 wraps discuss Item Response Theory, a classic approach for assessment in tests. It is used to assess students’ current knowledge of a topic and it assumes no learning is occurring between items. Through exploring foundational principles, and building models in the case study, this module will equip you with valuable skills to understand the validity of educational assessments. Finally, the badge activity will help you reflect on how these techniques could be applied to research and practice.\n\n\n\n\nConceptual\nOverview\nItem Response Theory and ELO\n\n\n\nCode Along\nComing soon!\n\n\n\nReadings &\nDiscussion\nEssential Readings\n\n\n\nCase Study\nIRT in R\n\n\n\nBadge\nApply IRT in practice\n\n\n\nModule Survey\nFeedback Form After Finishing Module",
    "crumbs": [
      "Home",
      "Curriculum",
      "Knowledge Tracing"
    ]
  },
  {
    "objectID": "curriculum-knowledge-tracing.html#module-4-deep-knowledge-tracing",
    "href": "curriculum-knowledge-tracing.html#module-4-deep-knowledge-tracing",
    "title": "Knowledge Tracing",
    "section": "Module 4: Deep Knowledge Tracing",
    "text": "Module 4: Deep Knowledge Tracing\nModule 4 discusses the application of deep neural networks in knowledge tracing, called Deep Knowledge Tracing (DKT). It is a growing area and has dozens of variants. While deep neural networks are becoming popular and every paper claims good performance, we must be cautious and carefully understand this technique and its strengths and weaknesses before using it. Our essential readings and case studies cover selected current issues and approaches in Deep Knowledge Tracing (DKT). In the hands-on activities, you’ll be working to add a dataset to the implementation of the DKT model from Gervet et al. (2020). Finally, the badge activity will help you reflect on how these techniques could be applied to research and practice.\n\n\n\n\nConceptual\nOverview\nIntro to Deep Knowledge Tracing\n\n\n\nCode Along\nComing soon!\n\n\n\nReadings &\nDiscussion\nEssential Readings\n\n\n\nCase Study\nDKT in Python\n\n\n\nBadge\nApply DKT in Practice\n\n\n\nModule Survey\nFeedback Form After Finishing Module",
    "crumbs": [
      "Home",
      "Curriculum",
      "Knowledge Tracing"
    ]
  },
  {
    "objectID": "curriculum-knowledge-tracing.html#microcredential",
    "href": "curriculum-knowledge-tracing.html#microcredential",
    "title": "Knowledge Tracing",
    "section": "Microcredential",
    "text": "Microcredential\nThe culminating activity for the Knowledge Tracing Modules is designed to provide you some space for independent analysis of a self-identified data source. To earn your KT Microcredential, you are required to demonstrate your ability to formulate a basic research question appropriate to a KT context, wrangle and analyze relational data, and communicate key findings. Your primary goal for this analysis is to create a simple data product that illustrates key findings by applying the knowledge and skills acquired from the essential readings and case studies.\n\n\n\n\n\n\n\n\n\nMicrocredential\nComing soon!",
    "crumbs": [
      "Home",
      "Curriculum",
      "Knowledge Tracing"
    ]
  },
  {
    "objectID": "instruction-intro.html",
    "href": "instruction-intro.html",
    "title": "Teaching with LASER",
    "section": "",
    "text": "LASER scholars participated in daily activities during the Summer Institute and ongoing activities throughout the year to help them design a customized instructional plan. This plan is implemented during the academic year at their home institutions or other contexts. As part of these activities, the project team collaborates with participants to choose relevant topics, modules and activities, effective teaching methods (pedagogy), and suitable technology from our training resources that meet the needs of their learners.\nThe LASER BEAM team will also work with participants in aligning the chosen learning analytics topics, pedagogy, and technology with scholars’ context to ensure the modules are tailored to address the unique needs and preferences of their learners.\nDesign sessions will also provide opportunities for scholars to collaborate and plan with other participants to support developing their practice of teaching. After the Summer Institute, scholars will participate in monthly virtual check-ins to finalize plans that they will implement in the academic year.",
    "crumbs": [
      "Home",
      "Instruction",
      "Teaching with LASER"
    ]
  },
  {
    "objectID": "instruction-intro.html#shark-goals",
    "href": "instruction-intro.html#shark-goals",
    "title": "Teaching with LASER",
    "section": "SHARK Goals",
    "text": "SHARK Goals\n\nIf you’ve seen the movie Austin Powers, you’ll remember that Dr. Evil famously demanded “to have sharks with frickin’ laser beams attached to their heads!” Based on this ridiculous idea, our initial logo shown above included a shark above the program name, but our final design shown on the title page is (slightly) more subtle.\nWe also carried this idea through for our version of SMART goals, i.e., SHARK Goals, which is an instructional goal that you will establish during the Summer Workshop. Specifically, scholars will participate in Pedagogy and Design Sessions that will help them create an instructional plan for teaching colleagues or students within or beyond their home institution.\nThe first step in designing an instructional plan is to develop a SHARK Goal, which includes identifying learning analytics topics and/or techniques and LASER materials that support teaching these topics, approaches and techniques. The SHARK Goal should address the following components:\n\nSpecific. Identify specific learning analytics topics and/or techniques to teach others; \nHow To. Develop a plan for how to incorporate LASER materials into this instructional experience;\nAttainable. Ensure the plan is attainable during the academic year, preferably fall semester; \nRelevant. Make sure the plan is relevant to their professional goals; and,\nKeep Track. Help to keep track of feedback, information, and insights gained to help improve the curriculum.",
    "crumbs": [
      "Home",
      "Instruction",
      "Teaching with LASER"
    ]
  },
  {
    "objectID": "instruction-intro.html#instructional-formats",
    "href": "instruction-intro.html#instructional-formats",
    "title": "Teaching with LASER",
    "section": "Instructional Formats",
    "text": "Instructional Formats\nIn addition to developing a SHARK Goal, scholars select the format for their instruction. Formats will vary based on scholars’ SHARK Goal, which may include, but is not limited to, courses, webinars, and workshops. Scholars are encouraged to select formats that are appropriate for their institutional roles, contexts, expertise, professional goals and interests. For example, some scholars may want to incorporate LASER materials into an entire course that they currently teach or plan to teach. Other scholars may choose a format where the instructional plan will be implemented in one to four hours of instruction.\n\nCourses. Curriculum materials can be adopted and adapted by scholars to provide a 1-3 credit course at their home institutions.\nLessons or Units. In addition, modules activities can be embedded as individual lessons or short units of instruction within existing courses or programs.\nWorkshop. Others may wish to design professional development for faculty and/or other colleagues at their home institution that they implement in the form of a workshop. Another possibility is designing a presentation or workshop that is implemented at a professional conference.\nWebinar. Yet others may want to create professional development for colleagues at and beyond their home institution in the form of a virtual webinar.\n\nTo assist scholars in developing and implementing their instruction plans, scholars are provided a range of resources such as example course syllabi and webinar and workshop templates.",
    "crumbs": [
      "Home",
      "Instruction",
      "Teaching with LASER"
    ]
  },
  {
    "objectID": "instruction-intro.html#plan-development",
    "href": "instruction-intro.html#plan-development",
    "title": "Teaching with LASER",
    "section": "Plan Development",
    "text": "Plan Development\nBased on their SHARK goal and selected format, scholars design a customized instructional plan for teaching colleagues or students within or beyond their home institution. This aspect of the program provides an opportunity for scholars to apply their pedagogical knowledge and skills related to learning analytics using LASER materials. Instructional plans will be implemented during the academic year, preferably in the fall semester. \nScholars participate in daily Pedagogy and Design Sessions during the that will support them in creating an instructional plan. During the Summer Institute, templates will be provided to scholars to guide their planning. Scholars will use one of the following planning guides based on their SHARK Goal and selected format for implementation:\n\nSyllabus Instructional Plan\nInstructional Plan (1-4 hrs)\n\nDuring the academic year, scholars will continue planning, refining and finalizing instructional plans that will be implemented during the academic year, preferably in the fall. Scholars will participate in monthly check-ins with the LASER BEAM team to finalize plans and implementation of instruction.",
    "crumbs": [
      "Home",
      "Instruction",
      "Teaching with LASER"
    ]
  },
  {
    "objectID": "institute-intro.html",
    "href": "institute-intro.html",
    "title": "Goals and Objectives",
    "section": "",
    "text": "As the use of digital teaching and learning resources continues to expand, the volume and variety of data available to researchers presents new opportunities for understanding and improving STEM education. The LASER Institute aims to increase the capacity of early and mid-career scholars to leverage new data sources and apply advanced methods to support their research and teaching. Located at the Friday Institute for Educational Innovation, the LASER Institute is a collaborative effort between North Carolina State University, University of Pennsylvania, University of Florida and the University of Tennessee, Knoxville.\nThe LASER Institute focuses on building the capacity of scholars to conduct high-quality research in three primary domains:\n\nDisciplinary Knowledge: Scholars will deepen their understanding of LA methodologies, literature, applications and ethical issues as they relate to STEM education and equity.\nTechnical Skills: Scholars will develop proficiency with R, Python, Quarto, GitHub and other tools used for collaboration, reproducible research and computational analyses.\nSocial Capital: Scholars will expand their professional networks, connecting with researchers and experts in LA related fields, as well as other scholars focused on STEM education."
  }
]